{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-7qovRrodq",
    "outputId": "ef79fceb-0fb0-4e1e-944d-3c794e23e338",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install gensim\n",
    "# !pip install python-Levenshtein\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import collections\n",
    "# from wordcloud import STOPWORDS\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import string\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the next cell only if you want to train the model. \n",
    "# If already trained, Skip to the next cell and directly load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pQVgxtersseC"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"preprocessed_tokenized_training_data.csv\")\n",
    "train_data['concatenated_description'] = train_data['concatenated_description'].map(str)\n",
    "train_data_idf = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>concatenated_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>mlb cincinnati reds shirt size xl Not known de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>razer blackwidow chroma keyboard Razer keyboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>avaviv blouse Target adorable top hint lace ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>leather horse statues Not known new tags leath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24k gold plated rose Not known complete certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481656</th>\n",
       "      <td>1481656</td>\n",
       "      <td>1482530</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>free people inspired dress Free People lace sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481657</th>\n",
       "      <td>1481657</td>\n",
       "      <td>1482531</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>little mermaid handmade dress Disney little me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481658</th>\n",
       "      <td>1481658</td>\n",
       "      <td>1482532</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21 day fix containers eating plan Not known us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481659</th>\n",
       "      <td>1481659</td>\n",
       "      <td>1482533</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>world markets lanterns Not known 2 one see 2 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481660</th>\n",
       "      <td>1481660</td>\n",
       "      <td>1482534</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>brand new lux de ville wallet Not known new ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1481661 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  train_id  item_condition_id  price  shipping  \\\n",
       "0                 0         0                  3   10.0         1   \n",
       "1                 1         1                  3   52.0         0   \n",
       "2                 2         2                  1   10.0         1   \n",
       "3                 3         3                  1   35.0         1   \n",
       "4                 4         4                  1   44.0         0   \n",
       "...             ...       ...                ...    ...       ...   \n",
       "1481656     1481656   1482530                  2   20.0         1   \n",
       "1481657     1481657   1482531                  2   14.0         0   \n",
       "1481658     1481658   1482532                  2   12.0         0   \n",
       "1481659     1481659   1482533                  3   45.0         1   \n",
       "1481660     1481660   1482534                  1   22.0         0   \n",
       "\n",
       "                                  concatenated_description  \n",
       "0        mlb cincinnati reds shirt size xl Not known de...  \n",
       "1        razer blackwidow chroma keyboard Razer keyboar...  \n",
       "2        avaviv blouse Target adorable top hint lace ke...  \n",
       "3        leather horse statues Not known new tags leath...  \n",
       "4        24k gold plated rose Not known complete certif...  \n",
       "...                                                    ...  \n",
       "1481656  free people inspired dress Free People lace sa...  \n",
       "1481657  little mermaid handmade dress Disney little me...  \n",
       "1481658  21 day fix containers eating plan Not known us...  \n",
       "1481659  world markets lanterns Not known 2 one see 2 r...  \n",
       "1481660  brand new lux de ville wallet Not known new ta...  \n",
       "\n",
       "[1481661 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GInA3QoeJl9c"
   },
   "outputs": [],
   "source": [
    "train_data['concatenated_description'] = train_data['concatenated_description'].apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QpwHNf5dJ1Sv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab for Model-2: 18.39 mins\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Build the Word2Vec model\n",
    "# Continous bag of words\n",
    "# Train the Word2Vec model\n",
    "\n",
    "model2 = Word2Vec(vector_size=200, window=5, min_count=1, sg=0, workers=cores-1)\n",
    "model2.build_vocab(train_data['concatenated_description'], progress_per=1000)\n",
    "t = time.time()\n",
    "model2.train(train_data['concatenated_description'], total_examples=model2.corpus_count, epochs=20)\n",
    "print('Time to build vocab for Model-2: {} mins'.format(round((time.time() - t) / 60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jIy1sBOEOyu7"
   },
   "outputs": [],
   "source": [
    "model2.save(\"word2vec_cbow_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One can directly load the model from here instead of training the models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYAkgFhiOytT",
    "outputId": "d42bb6bc-14be-4a56-c6e5-8ca71172fd27"
   },
   "outputs": [],
   "source": [
    "#Loading a pretrained model\n",
    "\n",
    "model2 = Word2Vec.load(\"word2vec_cbow_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec2(doc):\n",
    "    return np.mean([model2.wv[word] for word in doc if word in model2.wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2 = train_data.copy()\n",
    "\n",
    "series = train_data_model2.concatenated_description.apply(avg_word2vec2)\n",
    "\n",
    "df = pd.DataFrame(series.apply(pd.Series))\n",
    "\n",
    "train_data_model2 = pd.concat([train_data_model2, df], axis=1)\n",
    "\n",
    "train_data_model2 = train_data_model2.drop(['concatenated_description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2.to_csv('avgword2vec_cbow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2 = pd.read_csv('avgword2vec_cbow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'train_id', 'item_condition_id', 'price',\n",
       "       'shipping', '0', '1', '2', '3',\n",
       "       ...\n",
       "       '190', '191', '192', '193', '194', '195', '196', '197', '198', '199'],\n",
       "      dtype='object', length=206)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2.drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'train_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100559</td>\n",
       "      <td>-0.614330</td>\n",
       "      <td>0.208602</td>\n",
       "      <td>0.571966</td>\n",
       "      <td>-0.131203</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>0.608419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075749</td>\n",
       "      <td>0.193744</td>\n",
       "      <td>0.494159</td>\n",
       "      <td>-0.073508</td>\n",
       "      <td>0.494414</td>\n",
       "      <td>-0.169989</td>\n",
       "      <td>0.131777</td>\n",
       "      <td>0.145828</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>-0.127633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.329170</td>\n",
       "      <td>-0.350506</td>\n",
       "      <td>0.272558</td>\n",
       "      <td>0.105843</td>\n",
       "      <td>1.208020</td>\n",
       "      <td>1.528792</td>\n",
       "      <td>-0.091454</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.339325</td>\n",
       "      <td>0.835479</td>\n",
       "      <td>0.271060</td>\n",
       "      <td>0.437964</td>\n",
       "      <td>1.127263</td>\n",
       "      <td>1.099126</td>\n",
       "      <td>-0.569234</td>\n",
       "      <td>-0.982572</td>\n",
       "      <td>-0.126194</td>\n",
       "      <td>-0.116404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.240003</td>\n",
       "      <td>-0.041858</td>\n",
       "      <td>0.145329</td>\n",
       "      <td>0.452647</td>\n",
       "      <td>0.760089</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.452785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418078</td>\n",
       "      <td>0.219362</td>\n",
       "      <td>0.174552</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>-0.374551</td>\n",
       "      <td>-0.620355</td>\n",
       "      <td>0.631266</td>\n",
       "      <td>-0.212377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101531</td>\n",
       "      <td>-0.345377</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.361317</td>\n",
       "      <td>-0.764579</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.777097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010613</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>1.474908</td>\n",
       "      <td>0.728149</td>\n",
       "      <td>1.006546</td>\n",
       "      <td>-0.213868</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>-0.457993</td>\n",
       "      <td>-0.727977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820777</td>\n",
       "      <td>-0.600387</td>\n",
       "      <td>-0.174789</td>\n",
       "      <td>-0.790316</td>\n",
       "      <td>0.611780</td>\n",
       "      <td>0.271854</td>\n",
       "      <td>0.250769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>0.078621</td>\n",
       "      <td>-0.048399</td>\n",
       "      <td>-0.540433</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.234550</td>\n",
       "      <td>-0.283534</td>\n",
       "      <td>-0.156189</td>\n",
       "      <td>0.549295</td>\n",
       "      <td>-0.314060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370407</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484753</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.842793</td>\n",
       "      <td>-0.549632</td>\n",
       "      <td>0.861718</td>\n",
       "      <td>1.395888</td>\n",
       "      <td>1.131525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391027</td>\n",
       "      <td>0.211749</td>\n",
       "      <td>-0.072331</td>\n",
       "      <td>1.241811</td>\n",
       "      <td>2.145595</td>\n",
       "      <td>1.513619</td>\n",
       "      <td>1.109203</td>\n",
       "      <td>-1.061759</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>-1.878718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370408</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.989117</td>\n",
       "      <td>-0.492069</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>0.631189</td>\n",
       "      <td>1.291212</td>\n",
       "      <td>-0.071031</td>\n",
       "      <td>0.779076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386589</td>\n",
       "      <td>0.272975</td>\n",
       "      <td>-0.883474</td>\n",
       "      <td>-0.305047</td>\n",
       "      <td>-1.207003</td>\n",
       "      <td>0.288548</td>\n",
       "      <td>-1.372537</td>\n",
       "      <td>-0.139790</td>\n",
       "      <td>1.139007</td>\n",
       "      <td>0.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370409</th>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.060849</td>\n",
       "      <td>0.345536</td>\n",
       "      <td>0.088263</td>\n",
       "      <td>0.149190</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.373666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325529</td>\n",
       "      <td>0.767687</td>\n",
       "      <td>0.523542</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.218952</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>-0.767223</td>\n",
       "      <td>0.097173</td>\n",
       "      <td>-0.474679</td>\n",
       "      <td>-0.750847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370410</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263113</td>\n",
       "      <td>-0.582247</td>\n",
       "      <td>0.410359</td>\n",
       "      <td>-0.201431</td>\n",
       "      <td>0.439368</td>\n",
       "      <td>1.350481</td>\n",
       "      <td>0.880811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339725</td>\n",
       "      <td>0.607348</td>\n",
       "      <td>-0.159939</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>1.756508</td>\n",
       "      <td>0.985768</td>\n",
       "      <td>0.587361</td>\n",
       "      <td>-0.796640</td>\n",
       "      <td>-0.361518</td>\n",
       "      <td>-1.248246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370411</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.829921</td>\n",
       "      <td>-0.804902</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.184616</td>\n",
       "      <td>0.737504</td>\n",
       "      <td>1.492387</td>\n",
       "      <td>-0.328706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602713</td>\n",
       "      <td>-0.324386</td>\n",
       "      <td>-0.225616</td>\n",
       "      <td>0.208637</td>\n",
       "      <td>-0.016791</td>\n",
       "      <td>-0.252122</td>\n",
       "      <td>-0.543555</td>\n",
       "      <td>0.542459</td>\n",
       "      <td>-0.926188</td>\n",
       "      <td>-1.731979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370412 rows Ã— 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_condition_id  price  shipping         0         1         2  \\\n",
       "0                       2    8.0         1 -0.100559 -0.614330  0.208602   \n",
       "1                       3   14.0         0 -0.329170 -0.350506  0.272558   \n",
       "2                       1   25.0         1 -0.240003 -0.041858  0.145329   \n",
       "3                       3   25.0         0 -0.101531 -0.345377 -0.117154   \n",
       "4                       1   12.0         1  0.820777 -0.600387 -0.174789   \n",
       "...                   ...    ...       ...       ...       ...       ...   \n",
       "370407                  1   20.0         1  0.484753  0.030433 -0.842793   \n",
       "370408                  1   44.0         0 -0.989117 -0.492069 -0.002195   \n",
       "370409                  3   15.0         1  0.183705  0.060849  0.345536   \n",
       "370410                  1   16.0         0 -0.263113 -0.582247  0.410359   \n",
       "370411                  1   17.0         1 -1.829921 -0.804902  0.084474   \n",
       "\n",
       "               3         4         5         6  ...       190       191  \\\n",
       "0       0.571966 -0.131203  0.016526  0.608419  ... -0.075749  0.193744   \n",
       "1       0.105843  1.208020  1.528792 -0.091454  ... -1.339325  0.835479   \n",
       "2       0.452647  0.760089  0.097341  0.452785  ...  0.418078  0.219362   \n",
       "3      -0.361317 -0.764579  0.917608  0.777097  ... -0.010613  0.054686   \n",
       "4      -0.790316  0.611780  0.271854  0.250769  ... -0.093859  0.078621   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "370407 -0.549632  0.861718  1.395888  1.131525  ... -0.391027  0.211749   \n",
       "370408  0.631189  1.291212 -0.071031  0.779076  ...  0.386589  0.272975   \n",
       "370409  0.088263  0.149190  0.014507  0.373666  ... -0.325529  0.767687   \n",
       "370410 -0.201431  0.439368  1.350481  0.880811  ... -0.339725  0.607348   \n",
       "370411  0.184616  0.737504  1.492387 -0.328706  ...  0.602713 -0.324386   \n",
       "\n",
       "             192       193       194       195       196       197       198  \\\n",
       "0       0.494159 -0.073508  0.494414 -0.169989  0.131777  0.145828  0.024475   \n",
       "1       0.271060  0.437964  1.127263  1.099126 -0.569234 -0.982572 -0.126194   \n",
       "2       0.174552 -0.024960 -0.002166  0.013162 -0.374551 -0.620355  0.631266   \n",
       "3       0.057820  1.474908  0.728149  1.006546 -0.213868  0.185430 -0.457993   \n",
       "4      -0.048399 -0.540433  0.852686  0.234550 -0.283534 -0.156189  0.549295   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "370407 -0.072331  1.241811  2.145595  1.513619  1.109203 -1.061759  0.059616   \n",
       "370408 -0.883474 -0.305047 -1.207003  0.288548 -1.372537 -0.139790  1.139007   \n",
       "370409  0.523542  0.516035  0.218952  0.475278 -0.767223  0.097173 -0.474679   \n",
       "370410 -0.159939  0.906151  1.756508  0.985768  0.587361 -0.796640 -0.361518   \n",
       "370411 -0.225616  0.208637 -0.016791 -0.252122 -0.543555  0.542459 -0.926188   \n",
       "\n",
       "             199  \n",
       "0      -0.127633  \n",
       "1      -0.116404  \n",
       "2      -0.212377  \n",
       "3      -0.727977  \n",
       "4      -0.314060  \n",
       "...          ...  \n",
       "370407 -1.878718  \n",
       "370408  0.010722  \n",
       "370409 -0.750847  \n",
       "370410 -1.248246  \n",
       "370411 -1.731979  \n",
       "\n",
       "[370412 rows x 203 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"avgword2vec_sg.csv\" --> Will be used for \"train_test_split\", Contains 0.03 of entire dataset. \n",
    "## Generated from extracting dataset \"preprocessed_tokenized_training_data.csv\" and then applying \"word2vec_cbow_model\" on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've our dataset ready for the Model-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_model2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e69f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['price']\n",
    "X = data.drop(columns=['price'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=1000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.245 total time= 7.8min\n",
      "[CV 2/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=1000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.036 total time= 7.7min\n",
      "[CV 3/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=1000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.168 total time= 7.9min\n",
      "[CV 4/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=1000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=-0.183 total time= 7.7min\n",
      "[CV 5/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=1000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.092 total time= 7.9min\n",
      "[CV 1/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, random_state=6, solver=lbfgs, validation_fraction=0.2;, score=0.071 total time= 7.6min\n",
      "[CV 2/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, random_state=6, solver=lbfgs, validation_fraction=0.2;, score=0.102 total time= 8.0min\n",
      "[CV 3/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, random_state=6, solver=lbfgs, validation_fraction=0.2;, score=0.122 total time= 7.9min\n",
      "[CV 4/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, random_state=6, solver=lbfgs, validation_fraction=0.2;, score=-0.078 total time= 7.7min\n",
      "[CV 5/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, random_state=6, solver=lbfgs, validation_fraction=0.2;, score=-0.196 total time= 8.1min\n",
      "[CV 1/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.312 total time=11.4min\n",
      "[CV 2/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.281 total time=11.1min\n",
      "[CV 3/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.277 total time=10.8min\n",
      "[CV 4/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.355 total time=10.9min\n",
      "[CV 5/5] END activation=relu, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.345 total time=11.2min\n",
      "[CV 1/5] END activation=relu, alpha=0.005, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=constant, max_iter=2000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=-0.025 total time=25.1min\n",
      "[CV 2/5] END activation=relu, alpha=0.005, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=constant, max_iter=2000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=-0.007 total time=25.2min\n",
      "[CV 3/5] END activation=relu, alpha=0.005, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=constant, max_iter=2000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=-0.046 total time=25.6min\n",
      "[CV 4/5] END activation=relu, alpha=0.005, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=constant, max_iter=2000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=-0.294 total time=25.2min\n",
      "[CV 5/5] END activation=relu, alpha=0.005, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=constant, max_iter=2000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=-0.069 total time=26.2min\n",
      "[CV 1/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, random_state=6, solver=adam, validation_fraction=0.2;, score=0.416 total time= 1.7min\n",
      "[CV 2/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, random_state=6, solver=adam, validation_fraction=0.2;, score=0.364 total time= 1.5min\n",
      "[CV 3/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, random_state=6, solver=adam, validation_fraction=0.2;, score=0.358 total time= 1.7min\n",
      "[CV 4/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, random_state=6, solver=adam, validation_fraction=0.2;, score=0.415 total time= 2.7min\n",
      "[CV 5/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, random_state=6, solver=adam, validation_fraction=0.2;, score=0.373 total time= 2.5min\n",
      "[CV 1/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=6, solver=adam, validation_fraction=0.2;, score=0.423 total time=  59.2s\n",
      "[CV 2/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=6, solver=adam, validation_fraction=0.2;, score=0.376 total time= 1.1min\n",
      "[CV 3/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=6, solver=adam, validation_fraction=0.2;, score=0.352 total time= 1.1min\n",
      "[CV 4/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=6, solver=adam, validation_fraction=0.2;, score=0.406 total time= 1.0min\n",
      "[CV 5/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=6, solver=adam, validation_fraction=0.2;, score=0.376 total time= 1.0min\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=adam, validation_fraction=0.2;, score=0.412 total time= 3.4min\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=adam, validation_fraction=0.2;, score=0.358 total time= 3.9min\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=adam, validation_fraction=0.2;, score=0.365 total time= 3.6min\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=adam, validation_fraction=0.2;, score=0.417 total time= 3.4min\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, max_iter=500, random_state=7, solver=adam, validation_fraction=0.2;, score=0.356 total time= 3.1min\n",
      "[CV 1/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=42, solver=adam, validation_fraction=0.2;, score=0.418 total time= 1.0min\n",
      "[CV 2/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=42, solver=adam, validation_fraction=0.2;, score=0.376 total time=  56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=42, solver=adam, validation_fraction=0.2;, score=0.363 total time=  47.8s\n",
      "[CV 4/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=42, solver=adam, validation_fraction=0.2;, score=0.418 total time=  58.3s\n",
      "[CV 5/5] END activation=relu, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50), learning_rate=adaptive, max_iter=500, random_state=42, solver=adam, validation_fraction=0.2;, score=0.369 total time=  56.5s\n",
      "[CV 1/5] END activation=logistic, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=invscaling, max_iter=1000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.238 total time=29.6min\n",
      "[CV 2/5] END activation=logistic, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=invscaling, max_iter=1000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.223 total time=29.2min\n",
      "[CV 3/5] END activation=logistic, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=invscaling, max_iter=1000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.194 total time=29.1min\n",
      "[CV 4/5] END activation=logistic, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=invscaling, max_iter=1000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.215 total time=29.2min\n",
      "[CV 5/5] END activation=logistic, alpha=5e-05, early_stopping=True, hidden_layer_sizes=(100,), learning_rate=invscaling, max_iter=1000, random_state=7, solver=lbfgs, validation_fraction=0.2;, score=0.219 total time=29.3min\n",
      "[CV 1/5] END activation=tanh, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.272 total time=18.8min\n",
      "[CV 2/5] END activation=tanh, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.235 total time=20.1min\n",
      "[CV 3/5] END activation=tanh, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.199 total time=37.4min\n",
      "[CV 4/5] END activation=tanh, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.254 total time=18.6min\n",
      "[CV 5/5] END activation=tanh, alpha=0.0005, early_stopping=True, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, random_state=42, solver=lbfgs, validation_fraction=0.2;, score=0.241 total time=18.6min\n",
      "Best Hyperparameters: {'validation_fraction': 0.2, 'solver': 'adam', 'random_state': 42, 'max_iter': 500, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50), 'early_stopping': True, 'alpha': 5e-05, 'activation': 'relu'}\n",
      "Mean Squared Error: 896.244683468908\n"
     ]
    }
   ],
   "source": [
    "# from scipy.stats import reciprocal\n",
    "model = MLPRegressor()\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50, 25)],\n",
    "    'max_iter' : [500, 1000, 2000],\n",
    "    'activation': ['relu', 'tanh','logistic'],\n",
    "    'alpha' : [0.00005, 0.005, 0.0005, 0.0001],\n",
    "    'solver':['lbfgs','adam'],\n",
    "    'random_state' : [6, 7, 42],\n",
    "     'early_stopping' : [True],\n",
    "     'validation_fraction' : [0.2],\n",
    "    'learning_rate': ['invscaling','constant', 'adaptive']\n",
    "}\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5, verbose=3)\n",
    "\n",
    "# Fit the data to perform random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Make predictions using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = MLPRegressor(alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50),\n",
    "             learning_rate='adaptive', max_iter=500, random_state=42,\n",
    "             validation_fraction=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layered Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a93d2",
   "metadata": {},
   "source": [
    "# KPCA Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e13cabde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAG1CAYAAAAfhDVuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpzElEQVR4nO3deVhU9f4H8PcwDPsOsggqirIpuKJpLoim3tIytdtVMdNcSpMyJbVMy8wlvS7pxaVcKjMrLc20fubWYqWilhuoqCAq+w4zMMPM+f2BTE6gzsEZhhner+fhAc45c+bzYcB5+z3fc45EEAQBRERERBbKytQFEBERERkTww4RERFZNIYdIiIismgMO0RERGTRGHaIiIjIojHsEBERkUVj2CEiIiKLxrBDREREFs3a1AWY2pkzZyAIAmQymalLISIiIj2pVCpIJBJ07Njxgds2+pEdQRBgrItIC4IApVJptP2bGvszb+zPvLE/88b+DPMc+u6/0Y/sVI/oREREGHzfcrkcSUlJaN26NRwcHAy+f1Njf+aN/Zk39mfe2N/DO3funN7bNvqRHSIiIrJsDDtERERk0Rh2iIiIyKIx7BAREZFFY9ghIiIii8awQ0RERBaNYYeIiIgsGsMOERERWTSGHSIiIrJoDSrsbNiwAWPGjLnvNgUFBZgxYwaioqLQtWtXvPPOO1AoFPVUIREREZmbBnO7iM8++wyrVq1Cly5d7rtdXFwcFAoFtm7diuLiYrz55puQy+VYunRpPVVKRERE5sTkYScrKwvz58/H8ePHERgYeN9tz5w5gxMnTmD//v0ICgoCACxYsAATJkzAa6+9Bh8fn3qomIiIiMyJyQ9jXbhwATKZDN9++y3at29/320TExPRpEkTbdABgK5du0IikeDUqVPGLpWIiIjMkMlHdmJiYhATE6PXtllZWfDz89NZZmNjAzc3N2RkZNS5BkEQIJfL6/z4e6meS2Spc4rYn3ljf+aN/Zk3c+1PEASUlVeiRK5ESZkKJXIViuVKlMhVKJWrUFauQoVSA1VlJUpLS+Fw5gxkMms80aM5gvxdDV6LRCLRa1uThx0xFAoFbGxsaiy3tbVFRUVFnferUqmQlJT0MKXdV2pqqtH23RCwP/PG/swb+zNvpu5PrRFQVq5BWbkaZeUayCs0kFeoIa/QoKxC9/vqD0EQ8wxVYa5CXoLBXd0NXn9tmaA2ZhV27OzsoFQqayyvqKiAg4NDnfcrk8nQunXrhymtVgqFAqmpqQgMDIS9vb3B929q7M+8sT/zxv7MmzH7U6s1KJGrUFiqRGFpBYpKlSgsVaKotOLOZ+WdZRUoVahEhpcq9rZSODvYwNlBdufDBk4OMjjaWcPOVgp1ZSUKCvLh5ekJB3tbRIV5w8VRv2Cir5SUFL23Nauw4+vri4MHD+osUyqVKCwshLe3d533K5FIHiosPYi9vb1R929q7M+8sT/zxv7Mm5j+KlRqFBSXI6+oHPnFdz6KypFfUo7C4goUllagoKQcxWVKUQHGSgK4Otne+bCBi6MtXB1t4KL9sK367PT3Mpm19L77lMvlSEpKQlhYkNFeP30PYQFmFnaioqKwfPlypKWloUWLFgCAEydOAAA6d+5sytKIiIjqRFWpQUHJXeHlTpD5Z6gpVaj03qeVBHBxsoWbky3cnG3h7mwLN2e7O5///t7NyRbOjjaQWukfHMxRgw47arUa+fn5cHZ2hp2dHdq3b49OnTph+vTpePvttyGXyzFv3jwMHTqUp50TEVGDIggCSuQq5BYqkFuoQN6d0JJXpEBOQRkycoqh2JOF4jL9Q4yNtRU8XO3g6WoPDxc7eLhUBRh3F90w4+Joa/EBRowGHXYyMjLQr18/LF68GMOGDYNEIsHatWvxzjvvYOzYsbC1tcWgQYMwZ84cU5dKRESNSPVZSdVBpvoj5+7vi8qhVKn12p+1VAL3O+HFw8UOni528HD9+3sP16pljvYyUYdvqEqDCjtLlizR+T4gIACXLl3SWebp6YkPPvigPssiIqJGRlFRqRNe8u4OMkVVnxUV+gUZVycbeLnZw6t6NMbVDk52VigtzEJkeBv4+7jB2cEGVhyJMZoGFXaIiIjqg7xchax8OXIKFMjKlyO74M5HvhxZ+QqUyGue+VsbZwdZVZC5E2aqv25y57Onqx1sZDUn81ZN4C1GoJ8zHBxsDd0e/QPDDhERWZxShQrZ+XcFmDufswsUyM6X6zXZ19HO+u8gc1egaeJmDy93e3i62MHOlm+j5oCvEhERmZ0KlRpZeWXIzJMjM68MmflynXBTVl75wH04O9jAx8Me3h4O8Hav+vDxcLjzvT0c7GT10AnVB4YdIiJqcARBQKlCjcs3ClFQlvd3qLkTcPKLyx+4D1cnm6oQcyfM+LjfCTZ3vrfnqEyjwVeaiIhMQlWpQU6BHBl3j9Dc+TojrwwVSjWAe9/30MHOGr6ejvD1dICvhyN8PP8enWniZs9DTKTF3wQiIjIaVaUGmXllyMgtw+3cUtzOKcOtnFJk5JUhr1ABzQOu9Ovlagc/L6eqQFMdbDwd4evpCGcHnoZN+mHYISKih6JWa5BdoMCtnFLczi1FRk4Zbt8JN9n58vsGGlsbKXw9/g4wfp4O8PF0hJujFfIy0xDRLtyibxdB9YNhh4iIHkgQBOQWluNWTglu51aNztzOKUNGbimy8uWoVN870djZSNHUywlNmziiaRMnNPVyhN+dDzcn21pHZ+RyOYpyOGpDhsGwQ0REWpVqDTJyy3AzuwTpWaVIzy7BzexS3Mouue9F9GysreDn9XeYufuzu3PtgYaovjDsEBE1QvJyFW5ml+LmnTCTnlX1OSO3DOp7HHeSWkng6+kI/yZ3Rmm0ocYJnq52vAIwNVgMO0REFqy4TIkbmcVIyyypCjZ3Rmvyiu596ra9rRT+3s5o5u2EAG9nNPOp+uzn5QhrqVU9Vk9kGAw7REQWQF6uQnpWCdIyS5CWWYwbGSW4kVWM/OKKez7GzdkWzbydEeDjhABvJzTzdkYzH2d4utrxsBNZFIYdIiIzoqpU42Z2KS6n5eLPi0X49tQZ3MypumrwvXh7OKC5jzOa+zhXhZo7n50cbOqxciLTYdghImqANBoBmXlluJ5RjBsZxdoRm9u5ZdDozKkp0X7l4WKL5r4uaOHrgha+zmjh54JmPs68UjA1evwLICIyMUVFJdIyinHtdhGu3y7G9dtFSMsoRrmy9rOfnOxlCPB2hJONCpEhzdCmuSea+7rAxZEjNUS1YdghIqongiAgp1CB1NvVwaYq3GTmlUGo5QQoG2srNPdzQaCvC1r4Od8ZtXGGh4sdFAoFkpKSEBbWjBfdI3oAhh0iIiOoPgyVcrMQKTeLkJJeiOu3i1CqUNW6vYeLLVo2db3z4YKWTV3R1MsRUp79RPTQGHaIiB6SIAjIyCvD1fQiXLlZiKt3PsrKK2tsK7WSoJmPMwKbuqDVXcHG1cnWBJUTNQ4MO0REIgiCgMw8OVLSC++M2tw72MisrdCyqQuCAtzQJsANrfxd0dzXGTJrqQkqJ2q8GHaIiO5BEARk5ctxJb0q0FxJL8TVW0Uoq+VQlMzaCoF+LmjdzA2tA6o+mvs68yJ8RA0Aww4R0R2lChUu3yjA5RsFuJRWgCvpBSgqVdbYzlpaNWLTOsCtatSmGYMNUUPGsENEjVKlWoPUjGJtsLmUVoBbOaU1trOWSu6M2LijdYDrnREbF8isGWyIzAXDDhE1CkWlFUhOzUfSnY+U9EIoKzU1tvP1dEBwc3eENHdHcAt3tGrqChsZ59gQmTOGHSKyOIIg4GZ2KU5fLcPR5Au4kl6EWzllNbZztJchuJkbglvcCTfN3XlWFJEFYtghIrNXoVLjyo0C7ahNcmo+SuTVk4gLtNs183FGeEsPhLbwQGigO5p6OcHKije8JLJ0DDtEZHbk5SpcvJ6Pcym5uHAtD1dvFaJSrXsJYhuZFfzcrdExtCki2/ggNNADzrzxJVGjxLBDRA1emUKFi9fzcO5qHs5dzcW1m4XQ/OP2Cu7Otghr6YGwQE+Et/SAr5sMV65cQlhYG95OgaiRY9ghogZHn3Dj5+mIdkGeaBfkifCWnvDxcIBE8vchKblcXs9VE1FDxbBDRCYnL1fhwrU8nE3Jxfmrubh2q6hmuPFyRLtWnoho7YV2rbzQxN3eNMUSkdlh2CGielep1uDKjUL8eTkbf17JwaW0Aqj/kW78vBwREeSFiCBPtAvygpcbww0R1Q3DDhEZXfWp4H9ezsGfl3Nw7mouFBW695Ly9XRAZOsmiGhdFXA8XRluiMgwGHaIyCiKSitw5lI2zlzOwV9XcpBXVK6z3tlBhsg2TdChTRN0CG4CX09HE1VKRJaOYYeIDEKjEZBysxCJSVk4lZyFK+mFEO46MiWztkLblp5oH1wVcFr5u/IaN0RULxpE2NFoNFi7di2++uorlJSUICoqCvPmzUOzZs1q3T41NRWLFi3C6dOn4eDggBEjRmDKlCmwtm4Q7RA1GsVlSpy5lI3E5CycuZRd46aZrZq6omNI1chNWEtP2PK2C0RkAg0iHSQkJGD79u1YsmQJfH19sWzZMkyYMAF79+6FjY3uRcCKioowevRotGrVCh9//DEUCgXeeustZGZmYtGiRSbqgKhx0GgEXLtVhFPJWUhMysLlGwU6Z0052FmjQ3ATdAn1QadQb867IaIGweRhR6lUYvPmzZg5cyaio6MBACtXrkSvXr1w4MABDB48WGf7b775BnK5HKtXr4aHhwcAYOHChRg1ahSmTJmCgICA+m6ByKIpVWqcTcnF8QuZOHEhE/nFunNvAv1c0DnUG53DfBAW6AFrKe8GTkQNi8nDTnJyMsrKytC9e3ftMhcXF4SHh+PkyZM1wk5aWhpatWqlDToAEB4eDgBITExk2CEygKLSCpxKzsLxC5k4nZyNcqVau87eVor2bZqgS5gPOoX48Ho3RNTgmTzsZGZmAgD8/Px0lnt7e2vX/XN5dnY21Go1pNKq4/+3bt0CAOTl5Rm5WiLLdTu3FMfPZ+L4hUwkXc/TOTzl4WKHbm190a2dLyJbe0Fmzbk3RGQ+TB52FAoFANSYm2Nra4uioqIa2//rX/9CQkICFi9ejNdeew1yuRwLFy6EtbU1VCpVje31IQiCUS4tX91b9WdLw/7Mm1wuR0aBEonfJ+HMlQLcyinTWd/cxwlRYU3QObQJWjV10d6KQaWsgEpZ2x4bFkt//difeWN/D08QBJ1bxNyPycOOnZ0dgKq5O9VfA0BFRQXs7WsOjwcGBmL16tWYN28ePvvsMzg4OGDatGlISUmBs7NznWpQqVRISkqqWwN6SE1NNdq+GwL2Zz4EQUBGgQoXbyhw8YYC+aV/X9jPSgK08LZFSIAdQvzt4e5kDUAFZfFtJBffNl3RD8mSXr/asD/zxv4ezj8HSu7F5GGn+vBVdnY2mjdvrl2enZ2NkJCQWh8TExODmJgYZGdnw83NDZWVlViyZMk9T1V/EJlMhtatW9fpsfejUCiQmpqKwMDAWoObuWN/5kEQBFy7XYw/zmfj+IUsZBX8/T8taynQPsgT3SP90DHYC072MhNWaliW8vrdC/szb+zv4aWkpOi9rcnDTmhoKJycnHD8+HFt2CkuLsbFixcRGxtbY/vExESsXr0aW7Zsgbe3NwBg//79sLe3R6dOnepUg0QigYODQ92beAB7e3uj7t/U2F/DIwgCrqQX4thft3Hs7G1k5f99mNZGJkWXMG90CfGCI/LQIbKt2fUnhjm+fmKwP/PG/upO30NYQAMIOzY2NoiNjcXy5cvh4eEBf39/LFu2DL6+vhgwYADUajXy8/Ph7OwMOzs7tGrVCpcuXcLSpUvx3HPP4dKlS1i4cCEmT54MJycnU7dDZFLpWSU4evomfjp9s0bAiQrzwaPtm6JLmA/sba0hl8uRlFRgwmqJiOqHycMOAMTFxaGyshJz585FeXk5oqKisGnTJshkMty8eRP9+vXD4sWLMWzYMHh4eGD9+vVYsmQJBg8ejCZNmuDll1/G888/b+o2iEwiv7gcP5+5hZ9OpyPl5t+T+m1tqgJOz/b+6BzqDTvbBvHnTkRU7xrEv35SqRTx8fGIj4+vsS4gIACXLl3SWdapUyd8+eWX9VUeUYMjL1fhj/MZOHrqJv66kqM9TVxqJUGnUG9EdwpA17a+sLNpEH/iREQmxX8JicxEpVqDPy/n4MipdPxxPhNK1d8X+gtt4Y7ozs3Qs31TuDrZmrBKIqKGh2GHqIG7kVmMH0/cwJFT6To32vRv4ojozs3Qp2MA/LwcTVghEVHDxrBD1ADJy1X45c9b+PHEDVxK+3sSsZuzLXp38Ed05wC0DnATdTYCEVFjxbBD1EAIgoCL1/Px44k0/PrXbVTcuR+V1EqCqHAfPNatBTqHeEPKG20SEYnCsENkYkWlFTh44gZ+PJGmc8sG/yZOGNCtOfp2aQZ3Z7v77IGIiO6HYYfIBARBQHJqAfb/dh2//nUblWoNAMDORopeHfzxWNcWCA1052EqIiIDqHPYuXr1Ko4dO4bs7GyMGTMG6enp2qshE1HtFBWVOHr6JvYfu47UjGLt8jbN3DCoeyB6tm8KBzvLuWUDEVFDIDrsaDQazJs3D7t27dLecbT6TuQ3btzAtm3b4Ovra4xaicxWWmYxvv8tFYcT06GoqLr5po21Ffp0CsC/egSiTTN3E1dIRGS5RIedhIQE7N27FwsXLkR0dDQeffRRAEB8fDymTp2KlStXYunSpQYvlMjcqDUCTlzIxLe/XMX5q3na5U29HPH4oy3Rr0szODnod8deIiKqO9FhZ9euXYiLi8Pw4cOhVv99UbOwsDDExcVh+fLlBi2QyNzIy1U4eOIG9v56DZl5VfensrKSoFtbXzzeIxCRrZvAyopzcYiI6ovosJObm4uwsLBa1/n4+KC4uLjWdUSWLitfju9+vYYDx9MgL686VOVkL8Og7oF44tGW8HKzN3GFRESNk+iw06JFC/z000/o0aNHjXUnTpxAixYtDFIYkTkQBAFJqfnY8/NV/HEuQ3uPKv8mTniqdyv07dyMN+AkIjIx0f8Kjx07FvPmzYNKpULfvn0hkUiQlpaG48ePY/PmzZg9e7Yx6iRqUNQaAX+cz8DXR67g8o1C7fIObZrgqT5B6BTizUNVREQNhOiw88wzzyA/Px/r1q3D559/DkEQ8Nprr0Emk2HChAkYOXKkMeokahBUlWocTkzHN0dTtBcAlFlbIbpTAJ7sHYRAPxcTV0hERP9Up/H1yZMnY/To0Thz5gwKCwvh4uKC9u3bw83NzcDlETUM8nIVvv8tFd/+chX5xRUAAEd7GZ54tCUG92zJKxwTETVgdQo7p06dwh9//IGpU6cCAC5evIj58+dj4sSJaNeunUELJDKlsnI1dvyYggMn0lF2Z9Kxp6sdhvYJwoBuLXgBQCIiMyA67Pz000+YOnUqIiIitGFHIpEgNTUVo0aNwubNm9GlSxeDF0pUn4pKK/DVwSv4/vdMKCurZh0383HCsOg26NMpADJr3oyTiMhciA47a9aswRNPPIElS5Zol4WFhWHPnj2YNWsWVqxYge3btxu0SKL6UlRagW+OpmDfsesov3PX8UBfZ4waFIpubf046ZiIyAyJDjtXr17FjBkzar1B4dChQ7WjPUTmpNaQ4+eMR9rYYGj/jnB0dDRxhUREVFeiw46zszOuX7+O7t2711iXnp4OBwcHgxRGVB/k5Srs/ukqdv90VXvPqqAAV4waEIq2gc5ITk7mnceJiMyc6LDz2GOPYfXq1fDz80Pfvn21y3/55ResXr0aAwYMMGiBRMZQoVJj36/XsfPwFZTIlQCAVv6uGD0oFFFhPpBIJJDL5SaukoiIDEF02Jk+fTrOnTuHl156CTKZDG5ubigsLERlZSXat2+PGTNmGKNOIoOoVGvw44kb2HHgEvKLywFUXe049l+h6BHRlHNyiIgskOiw4+TkhB07duCnn37CqVOnUFRUBGdnZ3Tp0gXR0dGwsuJZKtTwCIKA385m4ON9F5GRV3UxwCbu9hg1IAR9OzeDVMrfWyIiS1Wn6+xYWVmhb9++OoexiBqqS2n52PTtBSSl5gMA3Jxs8e/+wRjUvQVk1lITV0dERMZWp7Bz7NgxHDlyBAqFAhqNRmedRCLBokWLDFIc0cPIzpfj430X8fOftwAAtjZSDItujaejW8OeN+ckImo0RP+Lv3nzZrz//vuwtbWFh4dHjTNVeOYKmZpSpcauIynYeegylJUaSCRAvy7NEfuvUHi62pu6PCIiqmeiw862bdswZMgQvPfee7CxsTFGTUR1duJCJj7ccw6ZeVVnUkUEeWHCU+3Qyt/VxJUREZGpiA47ubm5GDFiBIMONSi3c0vx4e7zSEzKAlB1/6oXhrRDzw5NOdpIRNTIiQ474eHhuHLlCrp162aMeohEKVdW4qtDV/D1kRRUqjWwlkrwVO8gPPtYCOflEBERgDqEnTfeeAOvvvoqHBwc0L59e9jb15wD0bRpU4MUR3Q/py9lI2HnX8jKrzpk1TG4CSY9HYEAb2cTV0ZERA2J6LAzcuRIaDQavPHGG/c8PJCUlPTQhRHdS2FJBTZ9ex5HT98EAHi52mHi0Ah0j/DjISsiIqpBdNhZuHChMeogeiBBEHDo5A1s3nsBJXIVJBJgSM9WGD0oFA52MlOXR0REDZTosPP0008bow6i+7qVU4qEnX/hbEouAKBlUxe8/EwHBDd3N3FlRETU0NVpBmdWVhZOnToFpVKpXabRaKBQKJCYmIiVK1carEBq3NQaAXt+uoptPyRBVamBjUyK0QND8VTvVrzFAxER6UV02Pnhhx8wc+ZMVFZWaudHCIKg/bpVq1ai9qfRaLB27Vp89dVXKCkpQVRUFObNm4dmzZrVun1eXh4WLVqEY8eOQRAE9OjRA7Nnz4aPj4/YVqiBu51TilU7zmhv89AxuAmmjGgPX09HE1dGRETmRPR/jdevX4+2bdvi66+/xrBhw/DUU09h3759iI+Ph1QqxRtvvCFqfwkJCdi+fTveffdd7NixAxqNBhMmTNAZNbrbq6++itu3b2PLli3YsmULbt++jalTp4ptgxowjUbAtz9fxbT/HkVSaj7sba0x7d8d8M6k7gw6REQkmuiwc/36dUycOBHh4eHo1q0bkpOTERQUhPHjx+O5557D+vXr9d6XUqnE5s2bERcXh+joaISGhmLlypXIzMzEgQMHamxfXFyMEydOYOLEiQgLC0N4eDgmTZqEc+fOobCwUGwr1ADlFSnw1obf8OGe81Cq1OjQpgnWxvfFgG4teKYVERHVieiwY2VlBVfXqkvvt2jRAteuXdPeDLR3795ISUnRe1/JyckoKytD9+7dtctcXFwQHh6OkydP1tjezs4Ojo6O2L17N0pLS1FaWoo9e/agZcuWcHFxEdsKNTAnLmRi2vKjOJuSC1sbKV4aHokFk7vD293B1KUREZEZEz1np1WrVjh9+jSioqLQqlUrKJVKJCcnIzw8HMXFxfc8/FSbzMxMAICfn5/Ocm9vb+26u9nY2GDJkiWYN28eunTpAolEAm9vb2zbtg1WVnWfrCoIAuRyeZ0ffy8KhULns6UxVH9KlRrb/u8K/u94OgAg0M8ZrzwTgaZNHE36s+PrZ97Yn3ljf+atPvq7e77wg4gOO//5z38wf/58yOVyTJ8+HY888gjmzJmDESNGYNu2bWjbtq3e+6r+IfzzPlu2trYoKiqqsb0gCEhKSkLHjh0xYcIEqNVqrFy5ElOmTMHnn38OJycnse0AAFQqlVEvhJiammq0fTcED9NfbrEKX/2aj6xCFQCge6gT+rV3QVHuDRTlGqjAh8TXz7yxP/PG/sybsfvT9z6dosPOM888A6VSiZs3q65eu2DBAkyaNAnvvfce/P398eabb+q9Lzs7OwBVc3eqvwaAioqKWm9D8f3332Pbtm04cuSINtisX78effv2xc6dO/H888+LbQcAIJPJ0Lp16zo99n4UCgVSU1MRGBhYaz/m7mH7++N8Fjb9eAGKCjVcHW0wZXhbdGjjZYRK64avn3ljf+aN/Zm3+uhPzLSZOl1nZ/To0dqvmzdvju+//x4FBQXw8PAQtZ/qw1fZ2dlo3ry5dnl2djZCQkJqbJ+YmIiWLVvqjOC4urqiZcuWSEtLE9uGlkQigYOD8eaF2NvbG3X/pia2v0q1Blu+u4Bvf74GAGgX5InXY7vA3cXuAY80Db5+5o39mTf2Z96M2Z+Yk1b0Cju3b99GkyZNIJPJcPv27ftuB+h/I9DQ0FA4OTnh+PHj2rBTXFyMixcvIjY2tsb2vr6+2LdvHyoqKmBrawsAkMvluHnzJp588km9npNMK69IgaWfJGqvnTO8b2uM+VcYLxBIRERGo1fY6devH7744gtERkYiJibmgWlK3/kvNjY2iI2NxfLly+Hh4QF/f38sW7YMvr6+GDBgANRqNfLz8+Hs7Aw7OzsMHToUmzZtwquvvopXXnkFALBq1SrY2tpi2LBhej0nmU5yWj4WbTmBgpIKONpZ49WRnfBIO78HP5CIiOgh6BV2Fi1apL2i8eLFiw1aQFxcHCorKzF37lyUl5cjKioKmzZtgkwmw82bN9GvXz8sXrwYw4YNg7e3N7Zv345ly5Zh7NixsLKyQpcuXbB9+3Y4OzsbtC4yrMOJ6Vj71Z9QVWrQwtcZb47rBj8vXiCQiIiMT6+wc/fNPzMyMjBw4EAEBQUZpACpVIr4+HjEx8fXWBcQEIBLly7pLAsKChJ14UIyLbVGwKf7L2LXkaqJZN3a+uK1UZ14l3IiIqo3oicob9iwAW3btjVY2CHLVV5RiWXbTuHExaprJj3Trw1iB4XByopXQiYiovojelZo69atcf36dWPUQhakVK7EvI2/48TFTMisrTBjdGc893g4gw4REdU70SM7ffv2xYoVK/DLL78gJCSkxillEomEN+Zs5ApKyjFvw+9IzSiGo70M8194BGEtxV2WgIiIyFBEh521a9cCAI4dO4Zjx47VWM+w07hl58sxd8NvyMgtg5uzLRZM6o6WTV1NXRYRETViosNOcnKyMeogC5CeVYK3NvyGvKJyeHs44N3J3dHUq2638CAiIjIUg1/JrbS01NC7JDNwM7sEb6w7hryicjTzccL7L/dk0CEiogZB9MiOUqnExx9/jBMnTkCpVEIQBAB/3zk8JSUFf/31l8ELpYYrM0+OdzafQmFJBVo2dcG7k3vA1cnW1GUREREBqEPYef/997Ft2zYEBwcjPz8ftra28PDwwOXLl6FSqfDyyy8bo05qoApKK7Fm3ynkF5ejha8zgw4RETU4og9jHThwAOPGjcO3336L2NhYtGvXDl999RUOHDgAf39/aDQaY9RJDVBuoQJbD+Ugr6gcAd5OePdFBh0iImp4RIed/Px89O7dGwAQHByMc+fOAQB8fHwwadIk7N+/37AVUoOUX1yOBZtPoahMDT9PB7z30qNwd26Ydy0nIqLGTXTYcXZ2hlKpBAC0aNECGRkZ2knJgYGByMjIMGyF1OCUKVR4+8PfkVWggLuTFG+N6wwPFwYdIiJqmESHnS5duuDTTz+FQqFAixYtYG9vj4MHDwIAzpw5AycnnoFjyVSVaizaegLXbxfD1dEGY2KawNOVQYeIiBou0WFn6tSp+PPPPzFp0iRYW1tj1KhReOuttzBs2DCsXr0aAwcONEad1ABoNAJWbD+Nsym5sLeVYvZzHeHhJHqOOxERUb0S/U4VGhqK77//HpcvXwYAzJgxA05OTjh9+jRiYmIwadIkgxdJpicIAj769jx+/es2rKUSvPF8V7Rq6oSkolumLo2IiOi+6nQF5dDQUDRp0gRA1e0hXnzxRYMXRg3L7p+uYu8v1wAAr/6nEzoEe0Mul5u4KiIiogcTfRhr6NChGDJkCDZt2oSsrCxj1EQNzJ+Xs7H1uwsAgBeebIs+nQJMXBEREZH+RIedtWvXIigoCGvWrEFMTAzGjRuH3bt383/5Fio7X473Pz0FjQD0j2qOp3oHmbokIiIiUUSHnf79+2PVqlX47bffsHjxYtja2mLu3Ll49NFHER8fj19++cUYdZIJKFVqLP74BErkSrQOcMWLwyMhkUhMXRYREZEodT6VxsHBAU8++SSefPJJFBYWYu3atfj888/x3XffISkpyZA1kgkIgoB1u84i5WYRnB1sMGdsV9jKpKYui4iISLSHOm/4/Pnz2LdvH3744QdkZGQgLCwMTz31lKFqIxP64Y80HDx5A1YS4PUxneHt4WDqkoiIiOpEdNhJSUnBvn37sH//fty4cQPe3t4YMmQInnrqKbRp08YYNVI9S07Lx8ZvzgIAxjwejg7B3iauiIiIqO5Eh53BgwfDwcEBAwcOxNtvv41HHnmE8zgsSEFJOZZ8fBKVagE9Iv0wvG9rU5dERET0UESHneXLl6N///6ws+MtAixNpVqD9z9N1N7F/JVnOzLIEhGR2avTyA5Zpi8PXsb5q3mwt7XGG893hYOdzNQlERERPTTRp56TZbp+uwhfHqy6BcjLz7RHMx9nE1dERERkGAw7hEq1Bqt2nIFaI6B7hB96dfA3dUlEREQGw7BD+OZoCq7dKoKTvQwvDeOFA4mIyLIw7DRyOQUKfHHn8NXEoe3g7sKJ50REZFn0mqC8e/duUTsdOnRoHUohU9j63QVUKNUIb+mBvp2bmbocIiIig9Mr7MyePVvn++rDHIIg1FgGMOyYi/NXc/Hzn7dgJQEmP83DV0REZJn0CjuHDh3Sfp2UlIT4+HhMmTIF//rXv+Dt7Y2CggIcPnwYa9asweLFi41WLBmOWq3Bhm/OAQAGPhKIVv6uJq6IiIjIOPQKO/7+f5+dM23aNEyZMgUTJ07ULvPx8cHIkSOhVCqxbNky9OnTx/CVkkH98EcaUjOK4WQvw+hBoaYuh4iIyGhET1C+evUqwsPDa13XqlUr3Lx586GLIuMqLlNi2/dVd6aPHRQKVydbE1dERERkPKLDTmBgIPbu3Vvrui+++ALBwcGi9qfRaPDBBx+gV69e6NChAyZOnIj09PRat12zZg1CQkJq/ZgzZ47YVhqtbT8koVShQqCfCwZ1DzR1OUREREYl+nYRU6dOxSuvvILU1FT07dsX7u7uyM3NxYEDB5CSkoIPP/xQ1P4SEhKwfft2LFmyBL6+vli2bBkmTJiAvXv3wsbGRmfb8ePH4z//+Y/Osi1btuDzzz/H888/L7aVRiktsxj/93sqAGDS0xGQSnn1ASIismyiw86AAQPwv//9D//73/+watUqCIIAKysrdOzYEVu3bkWXLl303pdSqcTmzZsxc+ZMREdHAwBWrlyJXr164cCBAzXuw+Xo6AhHR0ft9xcvXsQnn3yCd999FyEhIWJbaZQ++yEZGgHoHuGHiCAvU5dDRERkdKLDDgDExMQgJiYGFRUVKCoqgpubW41RGH0kJyejrKwM3bt31y5zcXFBeHg4Tp48+cCbji5YsABdunTB008/Lfq5G6Mr6QX4/VwGJJKquTpERESNQZ3CDlA1UfnYsWPIyclBbGws0tPTERoaCicnJ733kZmZCQDw8/PTWe7t7a1ddy9HjhzBmTNnRF/wsDaCIEAulz/0fv5JoVDofDa1j7+7AADoGekHLxfrh+65ofVnaOzPvLE/88b+zFt99CcIgt7XhxMddjQaDebNm4ddu3Zpn2jQoEFISEjAjRs3sG3bNvj6+uq1r+ofwj9HhWxtbVFUVHTfx27ZsgV9+/ZFWFiY2BZqUKlUSEpKeuj93EtqaqrR9q2vtOwK/JWSBysJ0LGFYNB+G0J/xsT+zBv7M2/sz7wZuz99jyqJDjsJCQnYu3cvFi5ciOjoaDz66KMAgPj4eEydOhUrV67E0qVL9dqXnV3VfZiUSqX2awCoqKiAvb39PR93+/ZtHD9+HBs3bhRbfq1kMhlat25tkH3dTaFQIDU1FYGBgfftpz7sOn4KANC3sz8ejar90gFiNaT+jIH9mTf2Z97Yn3mrj/5SUlL03lZ02Nm1axfi4uIwfPhwqNVq7fKwsDDExcVh+fLleu+r+vBVdnY2mjdvrl2enZ193wnHBw8ehIeHhzZoPSyJRAIHBweD7Ks29vb2Rt3/gySn5uPc1XxIrSQYNTDc4LWYuj9jY3/mjf2ZN/Zn3ozZn5hbHIk+7zg3N/eeh458fHxQXFys976q5/gcP35cu6y4uBgXL15EVFTUPR+XmJiIrl27wtq6zlOOGpUdP14CAMR0aQZvD8v9oyIiIqqN6LDTokUL/PTTT7WuO3HiBFq0aKH3vmxsbBAbG4vly5fj0KFDSE5OxvTp0+Hr64sBAwZArVYjJycH5eXlOo+7ePEiQkN5NpE+Lt8owKnkbFhZSfBMP3EXfCQiIrIEoodGxo4di3nz5kGlUqFv376QSCRIS0vD8ePHsXnz5hp3SH+QuLg4VFZWYu7cuSgvL0dUVBQ2bdoEmUyGmzdvol+/fli8eDGGDRumfUxOTg7c3NzElt4o7Tx8BQAQ3SkAfl6OD9iaiIjI8ogOO8888wzy8/Oxbt06fP755xAEAa+99hpkMhkmTJiAkSNHitqfVCpFfHw84uPja6wLCAjApUuXaiz/66+/xJbdKN3KKcUf5zMAACNi2pi4GiIiItOo06SXyZMnY/To0Th9+jSKiorg4uKC9u3bc7Slgdnz01UIAhAV7oNmPs6mLoeIiMgk6jzD18nJCb179zZkLWRAhSUVOHTyBgDg6WjDn1ZPRERkLkSHnfLycqxbtw5HjhyBQqGARqPRWS+RSHDw4EGDFUh1s+/YdSgrNWjTzA3tWnmauhwiIiKTER123nvvPezcuRNdu3ZFWFgYrKx41+yGplxZiX3HrgOoGtURcy0CIiIiSyM67Bw4cADTp0/HpEmTjFEPGcChk+kokSvh4+GAHhF+D34AERGRBRM9LKNSqRAZGWmMWsgA1BoBe366CgB4qncQpFKOvBERUeMm+p2wZ8+e+Pnnn41RCxnAH+czkJFXBid7GR7r2vzBDyAiIrJwog9jPf7445g/fz7y8/PRvn37Wm/wNXToUEPURiIJgoBvjlTdGO3xR1vCzpa30yAiIhL9bvjqq68CAHbv3o3du3fXWC+RSBh2TCTlZiEu3SiAtdQKg3u2NHU5REREDYLosHPo0CFj1EEG8OOJquvq9Ij0g7uznYmrISIiahhEhx1/f39j1EEPqUKlxs+nbwIA5+oQERHdRa+wM2fOHEyZMgXNmjXDnDlz7rutRCLBokWLDFIc6e/3cxkoK6+Et7s9Ils3MXU5REREDYZeYef48eMYO3as9uv74QXsTOPgiTQAQP+o5rCy4mtARERUTa+wc/jw4Vq/poYhK1+Osym5kEiAflE8hEVERHQ3g19x7tq1a4beJT3A0VPpEAQgsrUXvD0cTF0OERFRgyJ6gnJhYSFWrVqFEydOQKlUQhAEAFXXeJHL5SgqKkJSUpLBC6XaCYKAo3cmJvft3MzE1RARETU8okd2Fi9ejJ07d6JFixaQSqVwdnZGREQEVCoViouLsWDBAmPUSfdw/XYxbmaXQmZthe68DxYREVENosPOL7/8gmnTpmHdunV49tln4evri1WrVuGHH35ASEgIUlJSjFEn3UP1qE7XcF842MlMXA0REVHDIzrsFBcXo2PHjgCAoKAgnD9/HgDg6OiI8ePH4+jRowYtkO5NoxHw85mqsNOnU4CJqyEiImqYRIcdd3d3lJSUAAACAwORl5eHwsJCAICPjw+ysrIMWiDd24XrecgrKoejnTW6hHmbuhwiIqIGSXTY6d69O9avX49bt26hefPmcHV1xTfffAMAOHLkCNzd3Q1eJNXulzO3AAA9IptCZi01cTVEREQNk+iw88orryAvLw+zZs2CRCLB5MmTsXTpUnTr1g1bt27F8OHDjVEn/YMgCDhxMRMA8Gj7piauhoiIqOGq072x9u/fj9TUVADAuHHj4OXlhdOnTyMyMhJPP/20oWukWly7VYS8onLY2UgREeRl6nKIiIgaLNFhBwDs7OwQGhqq/X7IkCEYMmSIwYqiBztxsWpuVIfgJrCR8RAWERHRveh9I1B98Uag9ePknUNYUeG+Jq6EiIioYdP7RqD64o1AjS+/uBxX0gsBAFFhPqYthoiIqIETfSNQMr3EpKpDWG2aucHdxc7E1RARETVsdZqzAwDXr1/HyZMnUVhYCC8vL3Tr1g3+/v6GrI3uofoQVte2PIRFRET0IKLDjlKpxOzZs/H9999rbwIKAFZWVnj22Wcxb948Hsoyokq1Bn9dyQEAdOEhLCIiogcSHXaWL1+OQ4cOYfbs2Rg4cCA8PDyQl5eHH374AatWrYKvry8mT55sjFoJwOUbBVBUqOHiaINWTV1NXQ4REVGDJzrs7Nu3D9OnT8fYsWO1y/z8/DBu3DhUVlbi888/Z9gxor+u5AIAIlp7wcqKI2hEREQPIvoKynK5HK1atap1XVhYGAoKCh66KLq36kNYHdo0MXElRERE5kF02Bk4cCC2bdsGjUZTY92ePXvQt29fgxRGNSkqKnEpLR8A0J5hh4iISC+iD2NFRERg9erVGDx4MIYMGQJvb28UFBTg0KFD+OuvvzB27FisXbsWQNU1d6ZOnXrf/Wk0GqxduxZfffUVSkpKEBUVhXnz5qFZs2a1bq9SqfDBBx9g9+7dKCkpQbt27fDmm28iLCxMbCtm58K1PFSqBXh7OMDX08HU5RAREZkF0WHn3XffBQAUFxdj9erVNdZv2bJF+7U+YSchIQHbt2/HkiVL4Ovri2XLlmHChAnYu3cvbGxsamz/9ttv4+jRo1iyZAmaNm2K1atXY+LEifj+++/h7Owsth2zUn0Iq31rL57xRkREpCfRYSc5OdlgT65UKrF582bMnDkT0dHRAICVK1eiV69eOHDgAAYPHqyzfXp6Onbt2oX169ejV69eAICFCxdi6NChOH/+PLp3726w2hqis3cmJ/MQFhERkf5Ez9mpvtv5vezfv1/vfSUnJ6OsrEwnpLi4uCA8PBwnT56ssf2xY8fg7OyM3r1762x/+PBhiw86RaUVuHa7CAAQ2YZ3OSciItKX6JGdp59+GrNnz8azzz6rs7ygoADz58/Hjz/+iMcff1yvfWVmVl0J2M/PT2e5t7e3dt3drl+/jmbNmuHAgQPYuHEjsrKyEB4ejtmzZyMoKEhsK1qCIEAul9f58feiUCh0Pj+Ms5erDmE19XKErVRjlHrFMmR/DRH7M2/sz7yxP/NWH/0JgqD3lA7RYWfgwIGYP38+jh49ivfeew8eHh44cOAA3nnnHZSXl+PNN9/Ue1/VP4R/zs2xtbVFUVFRje1LS0uRlpaGhIQEvP7663BxccG6deswatQo7N+/H56enmLbAVA16TkpKalOj9XHg0bD9HHsz6qfh4+rYNRa68IQ/TVk7M+8sT/zxv7Mm7H7q21ub21Eh50lS5agf//+ePvtt/Hkk08iIiICR48eRUxMDObNmwcfH/1vYWBnV3UTS6VSqf0aACoqKmBvb1+zWGtrlJaWYuXKldqRnJUrV6JPnz745ptvMGHCBLHtAABkMhlat25dp8fej0KhQGpqKgIDA2vtR4wdx6oO63WLDERYWMO4B5kh+2uI2J95Y3/mjf2Zt/roLyUlRe9t63Qj0P79+wMA4uLicOTIEYSHh2Px4sVwcXERtZ/qw1fZ2dlo3ry5dnl2djZCQkJqbO/r6wtra2udQ1Z2dnZo1qwZbt68WZdWAFSdNebgYLxTue3t7R9q/6pKDa7dKgYAtA/2NWqtdfGw/TV07M+8sT/zxv7MmzH7E3NWsugJyoWFhZgzZw6mTZuGiIgIvPXWW7h16xYef/xxUZOTASA0NBROTk44fvy4dllxcTEuXryIqKioGttHRUWhsrIS586d0y4rLy9Heno6WrRoIbYVs3HtViGUlRo4O9jAv4mTqcshIiIyK6LDzqBBg7Bv3z689tpr+PzzzzF69Gjs27cPEREReO211/Diiy/qvS8bGxvExsZqby6anJyM6dOnw9fXFwMGDIBarUZOTg7Ky8sBAF26dEGPHj0wa9YsJCYmIiUlBa+//jqkUimeeuopsa2YjaTUqqsmhwV68Po6REREIokOO82aNcM333yDiRMnwsqq6uFeXl5Yt24dlixZgtOnT4vaX1xcHEaMGIG5c+di5MiRkEql2LRpE2QyGTIyMtCzZ0+dEaM1a9aga9euePnllzFixAiUlpbik08+gYeHh9hWzEZ12AkNdDdxJUREROZH9JydL774Qhty/mno0KHo0aOHqP1JpVLEx8cjPj6+xrqAgABcunRJZ5mTkxPefvttvP3226Kex1wJgoCk61VhJ7xl3c42IyIiasxEhx0rKysolUrs3LkTv/32G3JycrBo0SKcOHECbdu2RWRkpDHqbLSy8uUoKKmAtVSC1s3cTF0OERGR2RF9GCs/Px/Dhw/He++9h7S0NJw9exbl5eU4evQoxowZgzNnzhijzkYr+c4hrCB/N9jKpCauhoiIyPyIDjvvv/8+ysrKsH//fnzzzTcQBAEA8MEHHyAiIgIffPCBwYtszC5q5+tY7pwkIiIiYxIddo4cOYJXXnkFLVq00DkzyNbWFuPHj8eFCxcMWmBjVz2yE9aSYYeIiKguRIediooKuLm51bpOKpVCpVI9bE10h7xchbSMqosJhnFkh4iIqE5Eh52IiAhs37691nV79+5Fu3btHrooqnIprQAaAfDxcICHi92DH0BEREQ1iD4b65VXXsHzzz+Pp556Cn369IFEIsF3332HNWvW4Ndff8VHH31kjDobpeS7LiZIREREdSN6ZKdLly7YsmUL7O3t8dFHH0EQBGzduhU5OTnYsGEDHnnkEWPU2ShxcjIREdHDq9ONQKOiorBjxw6Ul5ejqKgITk5OcHR0NHRtjZpaI+BSWgEAIJyTk4mIiOqsTmGnmp2dHezsOJfEGG5kFkNRUQl7W2s09xV3N3kiIiL6m+jDWFQ/qu+HFdLCHVIr3vyTiIiorhh2GqjqQ1ihLXgIi4iI6GEw7DRQ128XAQCCAlxNXAkREZF5Y9hpgFSVGqRnlQAAWjVl2CEiInoYdZqgnJ+fj02bNmnvev7RRx/h4MGDCA0NRf/+/Q1dY6OTnlWCSrUAR3sZmrjbm7ocIiIisyZ6ZCc9PR1PPvkkvvzyS/j4+CAvLw9qtRrXr19HXFwcjh49aoQyG5drt6oOYbVq6qpz/zEiIiIST/TIztKlS+Hp6YlPP/0UDg4O2ttD/Pe//0VFRQXWr1+P6OhoQ9fZqFzPqAo7Lf15yjkREdHDEj2y8/vvv2PKlClwcXGpMerw7LPP4sqVKwYrrrG6fqvq5p+cr0NERPTw6jRB2dq69gEhpVLJwy4PSRAEXLtzJlYrf4YdIiKih1Wne2Nt2LABcrlcu0wikUCj0eDzzz9Hp06dDFpgY5NToECZQgVrqQQB3s6mLoeIiMjsiZ6zM2PGDIwcORIDBgxAt27dIJFIsGnTJly9ehVpaWnYvn27MepsNKpHdZr5OENmzSsDEBERPSzR76bBwcHYuXMnunXrhuPHj0MqleK3335D8+bNsWPHDoSFhRmjzkbj+p0zsVpyvg4REZFBiB7ZUavVaNmyJf773/8ao55Gj/N1iIiIDEv0yE7Pnj2xcOFCnDt3zhj1NHqpGVVnYrVsytPOiYiIDEF02Bk8eDD+7//+D//+978xaNAgrF+/Hrdu3TJGbY1OubISWflVE79b+DLsEBERGYLosPPmm2/i559/xubNm9GlSxds2bIFjz32GGJjY/HVV1+hpKTEGHU2CjezSiEIgKuTDVydbE1dDhERkUWo0+k+EokE3bt3x8KFC/Hrr78iISEBfn5+eOedd9CrVy9D19ho3Lhz889mPjzlnIiIyFDqdCPQapWVlfj111/x/fff4+effwYAdO/e3SCFNUY3Mqvm6zRn2CEiIjIY0WFHEAT88ccf2LdvH3788UcUFRUhMjIScXFxePzxx+Hu7m6MOhuF6pGd5pyvQ0REZDCiw06vXr2Ql5eHpk2bYtSoUXjqqacQGBhohNIanxuZd8IOR3aIiIgMRnTYiYmJwZNPPokuXboYo55Gq7yiEtkFVWdiNfdl2CEiIjIU0WFnwYIFxqij0buZzTOxiIiIjEGvsNOvXz/873//Q2hoKPr163ffbSUSCQ4ePGiQ4hqTG1lVk5N5JhYREZFh6RV2unbtCkdHRwBAVFQUJBKJwQrQaDRYu3at9ho9UVFRmDdvHpo1a1br9t9++y3i4+NrLD906BACAgIMVld943wdIiIi49Ar7CxevFj79ZIlS+67rVqtFlVAQkICtm/fjiVLlsDX1xfLli3DhAkTsHfvXtjY2NTY/tKlS+jatStWrFihs9zDw0PU8zY0PBOLiIjIOERfVLBfv35ITk6udd3Zs2fRo0cPvfelVCqxefNmxMXFITo6GqGhoVi5ciUyMzNx4MCBWh9z+fJlhISEoEmTJjofUqlUbCsNCkd2iIiIjEOvkZ3vvvsOlZWVAIBbt27hwIEDtQae33//HSqVSu8nT05ORllZmc6FCF1cXBAeHo6TJ09i8ODBNR5z6dIlxMTE6P0c5qBcyTOxiIiIjEWvsHPu3Dl8/PHHAKomICckJNxz23Hjxun95JmZmQAAPz8/neXe3t7adXcrKipCVlYWEhMTsX37dhQUFCAyMhLx8fFo2bKl3s/7T4IgQC6X1/nx96JQKHQ+30taZgkEAXCyl0FmpTZKLcagb3/miv2ZN/Zn3tifeauP/gRB0HsOsV5hZ8aMGXjuuecgCAL69++PtWvXIiwsTGcbqVQKJycnODk56V1o9Q/hn3NzbG1tUVRUVGP7K1euAKhqcPHixSgvL8e6deswatQo7N27F15eXno/991UKhWSkpLq9Fh9pKam3nf9xRtV4cbVQWLUOozlQf2ZO/Zn3tifeWN/5s3Y/dU2t7c2eoUdGxsb+Pv7A6g668nb2xsymazu1d1hZ2cHoGruTvXXAFBRUQF7e/sa23fp0gW///473N3dtWlu7dq1iI6Oxtdff41JkybVqQ6ZTIbWrVvX6bH3o1AokJqaisDAwFr7qXYp5zqAfLT096gRIhsyffszV+zPvLE/88b+zFt99JeSkqL3tqIvKujv74+zZ8/i+PHjUCqVEAQBwN+Hgk6dOoUvv/xSr31VH77Kzs5G8+bNtcuzs7MREhJS62P+edaVvb09AgICkJWVJbYVLYlEAgcHhzo//kHs7e3vu//cIiUAoLmvq1HrMJYH9Wfu2J95Y3/mjf2ZN2P2J+YyOKLDzmeffYaFCxdqQ87drKys0LNnT733FRoaCicnJxw/flwbdoqLi3Hx4kXExsbW2P6LL77AihUrcOTIEe0Pr7S0FKmpqRgxYoTYVhqM27llAAA/L0cTV0JERGR5RJ96vm3bNvTu3RvHjx/H+PHj8e9//xt//vknVq9eDVtbWzz55JN678vGxgaxsbFYvnw5Dh06hOTkZEyfPh2+vr4YMGAA1Go1cnJyUF5eDgDo3bs3NBoNXn/9dVy5cgXnzp3DtGnT4OHhgWHDholtpcHIuBN2mjbRf74TERER6Ud02Ll58yZGjRoFV1dXtGvXDqdOnYKdnR0GDhyISZMm4ZNPPhG1v7i4OIwYMQJz587FyJEjIZVKsWnTJshkMmRkZKBnz57Yv38/gKrDXlu3boVcLsfIkSPx/PPPw9nZGZ988glsbc3zflLlFZXIL64Kc005skNERGRwog9jyWQy7WTiFi1aIC0tDSqVCjKZDJ07d8aWLVtE7U8qlSI+Pr7WW0AEBATg0qVLOsvatm2LzZs3iy27wcrIqxrVcXaQwclBv1nlREREpD/RIzthYWE4cuQIAKBly5bQaDT466+/AKDWa+PQ/VXP12nqxUNYRERExiB6ZGfcuHF4+eWXUVxcjEWLFqFfv354/fXXMWDAAOzduxedO3c2Rp0W63ZOKQBOTiYiIjIW0SM7/fv3x/r16xEUFAQAWLBgAQIDA7Fjxw60atUKb731lsGLtGTayckMO0REREYhemQHAKKjoxEdHQ0AcHd3t6g5NPVNe9o5z8QiIiIyCr3CzsmTJ0XtNCoqqk7FNEYZuVWHsTiyQ0REZBx6hZ0xY8bUuFLh3Tfgqv66+rM53t/JFKpOO68AwLBDRERkLHqFHbHXziH98LRzIiIi49Mr7HTt2tXYdTRKvE0EERGR8YmeoLx27doHbvPyyy/XqZjGJjtfDgDw9WDYISIiMhaDhh0nJyd4e3sz7OipOux4e1juHW+JiIhMTXTYSU5OrrFMLpcjMTERb7/9Nq+zI0JWAcMOERGRsYm+qGBtHBwc0Lt3b0ydOhXvv/++IXbZKFSP7Pi4M+wQEREZi0HCTrWmTZvi6tWrhtylxRIEAdnakR17E1dDRERkuep0BeV/EgQBmZmZ+Oijj+Dv72+IXVq8UoUKigo1AKAJR3aIiIiMRnTYCQ0NrXGBwWqCIPAwlp6y7hzCcne2ha1MauJqiIiILJfosDN16tRaw46TkxOio6MRGBhoiLosHs/EIiIiqh+iw860adOMUUejUz1fh5OTiYiIjKtOc3aysrJw/vx5lJSU1Lp+6NChD1NTo5DFkR0iIqJ6ITrs7N+/H7Nnz4ZSqax1vUQiYdjRQ3a+AgDDDhERkbGJDjurVq1CZGQk5syZAzc3NyOU1DjwMBYREVH9EB12srOzsWDBArRt29YY9TQKgiBoD2M1cec1doiIiIxJ9EUFO3ToUOstI0h/VdfYqQTAw1hERETGJnpkZ/78+XjxxRdRWlqKiIgIODjUfLOOiooySHGWqvq0czdeY4eIiMjoRIed1NRU5Obmau9+fvc1dwRBgEQiQVJSkuEqtECcr0NERFR/RIedpUuXonnz5pg4cSK8vLyMUZPFy+KZWERERPVGdNi5ffs21q9fjx49ehijnkZBewNQTk4mIiIyOtETlIODg5GRkWGMWhqN3MKqkZ0mbgw7RERExiZ6ZGfOnDmYOXMm1Go1OnToACcnpxrbNG3a1CDFWaq8oqqw48mwQ0REZHSiw864ceNQWVmJefPm3fPu55ygfH+5heUAAC9Xhh0iIiJjEx123n777XuGHHqwSrUGBSVVYcfTzc7E1RAREVk+0WFn2LBhxqij0SgoroAgANZSCVwdbU1dDhERkcUTHXZOnjz5wG14UcF7q56v4+FqDysrjpAREREZm+iwM2bMGEgkEgiCoF32z8NanLNzbzl3zsTycuUhLCIiovogOux88sknNZbJ5XIkJiZiz549WLNmjaj9aTQarF27Fl999RVKSkoQFRWFefPmoVmzZg987Lfffov4+HgcOnQIAQEBop7XVKpHdrx4JhYREVG9EB12unbtWuvy6OhoODg4YN26ddiwYYPe+0tISMD27duxZMkS+Pr6YtmyZZgwYQL27t0LGxubez7u1q1bWLBggdjyTY5nYhEREdUv0RcVvJ8uXbrgxIkTem+vVCqxefNmxMXFITo6GqGhoVi5ciUyMzNx4MCBez5Oo9EgPj4ebdu2NUTZ9SpXe40dHsYiIiKqDwYNO4cPH4ajo6Pe2ycnJ6OsrAzdu3fXLnNxcUF4ePh9J0KvX78eKpUKkydPfqh6TSFPO2eHIztERET1QfRhrOeee67GMo1Gg8zMTNy6dQsTJ07Ue1+ZmZkAAD8/P53l3t7e2nX/dPbsWWzevBk7d+5EVlaWiMrvTRAEyOVyg+zrbgqFQucz8PcEZSc7iVGesz7V1p8lYX/mjf2ZN/Zn3uqjP0EQ9L7un+iwc/dZWNWsrKwQHByMyZMnY/jw4Xrvq/qH8M+5Oba2tigqKqqxvVwux8yZMzFz5kwEBgYaLOyoVCqjnkGWmpoKANBoBOQXV83ZyctKh6rkttGesz5V92ep2J95Y3/mjf2ZN2P3d7+5vXcTHXY+/fTTGssqKythbS16V7Czq5q3olQqtV8DQEVFBeztax7mWbhwIVq2bIn//Oc/op/rfmQyGVq3bm3QfQJVYS41NRWBgYGwt7dHfnE5BOEWrKwkiOrY1uyvs/PP/iwN+zNv7M+8sT/zVh/9paSk6L2t+IQCYOPGjUhMTMTGjRsBAKdOncKMGTPw4osvIjY2Vu/9VB++ys7ORvPmzbXLs7OzERISUmP7Xbt2wcbGBh07dgQAqNVqAMDgwYPx4osv4sUXX6xLO5BIJHBwcKjTY/Vhb28PBwcH3MytAAB4uNjByUn/uU0NXXV/lor9mTf2Z97Yn3kzZn9ibl0lOuxs3rwZq1at0gk1zZs3x6BBg7BkyRLY2trimWee0WtfoaGhcHJywvHjx7Vhp7i4GBcvXqw1NP3zDK2//voL8fHx2LhxI4KDg8W2Uu9yeUFBIiKieic67OzYsQOvvvoqJk2apF3m5+eHuXPnwsvLC1u3btU77NjY2CA2NhbLly+Hh4cH/P39sWzZMvj6+mLAgAFQq9XIz8+Hs7Mz7Ozs0KJFC53HV09ibtq0Kdzc3MS2Uu+qw44nLyhIRERUb0Sfep6VlYWIiIha17Vv3x43b94Utb+4uDiMGDECc+fOxciRIyGVSrFp0ybIZDJkZGSgZ8+e2L9/v9gyG6TcIl5QkIiIqL6JHtnx9/fH77//rnNtnGonT56Er6+vqP1JpVLEx8cjPj6+xrqAgABcunTpno/t1q3bfdc3NNpr7PCCgkRERPVGdNj597//jWXLlkGlUqF///7w9PREfn4+jhw5gi1btmDGjBnGqNMi5PK+WERERPVOdNh5/vnnkZWVhU8//RRbt27VLpdKpRg7dizGjRtnyPosSvU1djxcOLJDRERUX+p06vmsWbMwZcoU/PnnnygsLISLiwsiIyPh7u5u6PoshiAIyC9i2CEiIqpvdQo7AODs7IxevXoZshaLVlZeCWWlBgDgzrBDRERUbwx6I1C6t4I7h7Ac7WWwlUlNXA0REVHjwbBTT/6er2Nr4kqIiIgaF4adelIddtydeQiLiIioPjHs1JMCnolFRERkEgw79SS/+O+bgBIREVH9YdipJ9UjOzwTi4iIqH4x7NSTPE5QJiIiMgmGnXrCkR0iIiLTYNipJwUlnKBMRERkCgw79UBRUQlFhRoA4O7Mw1hERET1iWGnHhSUVJ2JZW8rhYOdzMTVEBERNS4MO/Wg8E7Y4QUFiYiI6h/DTj0oKFEC4ORkIiIiU2DYqQeFpbygIBERkakw7NSDAl49mYiIyGQYdupB9QRlXlCQiIio/jHs1IPCUs7ZISIiMhWGnXqgHdnh2VhERET1jmGnHmjDjivDDhERUX1j2DEyVaUAeXklAF49mYiIyBQYdoxModQAAKysJHC059WTiYiI6hvDjpGV3wk7jnYySCQSE1dDRETU+DDsGFn1yI4TR3WIiIhMgmHHyMpVd0Z2HBh2iIiITIFhx8jKObJDRERkUgw7RlZ9GIuTk4mIiEyDYcfIypUCAI7sEBERmQrDjpHxMBYREZFpMewYmXaCMsMOERGRSZg87Gg0GnzwwQfo1asXOnTogIkTJyI9Pf2e21+4cAFjx45Fx44d8cgjj2DevHkoKSmpx4rF0Z567mBj4kqIiIgaJ5OHnYSEBGzfvh3vvvsuduzYAY1GgwkTJkCpVNbYNjc3F+PGjYO/vz++/vprJCQk4NSpU5g9e7YJKteP9jCWHUd2iIiITMGkYUepVGLz5s2Ii4tDdHQ0QkNDsXLlSmRmZuLAgQM1tr916xZ69uyJBQsWoGXLlujUqRP+/e9/49ixYyaoXj/VE5R5nR0iIiLTMGnYSU5ORllZGbp3765d5uLigvDwcJw8ebLG9u3bt8eKFStgbW0NALh69Sr27NmDRx99tN5qFotXUCYiIjIta1M+eWZmJgDAz89PZ7m3t7d23b0MHDgQqamp8Pf3x9q1a41W48Pi2VhERESmZdKwo1AoAAA2NrqTd21tbVFUVHTfxy5fvhwKhQLLli3Dc889hz179sDR0bFOdQiCALlcXqfH3k9pmRzKyqrDWFaoNMpzmFL161f92dKwP/PG/swb+zNv9dGfIAh632DbpGHHzs4OQNXcneqvAaCiogL29vb3fWxERAQAYO3atejTpw9+/PFHDB06tE51qFQqJCUl1emx9yOvUGu/vpGaAqmVZd71PDU11dQlGBX7M2/sz7yxP/Nm7P7+OVhyLyYNO9WHr7Kzs9G8eXPt8uzsbISEhNTY/tq1a7hx4waio6O1y3x8fODm5oasrKw61yGTydC6des6P/5eUm/lA8iAnY0U7dqGG3z/pqZQKJCamorAwMAHhlNzxP7MG/szb+zPvNVHfykpKXpva9KwExoaCicnJxw/flwbdoqLi3Hx4kXExsbW2P63337D+++/j19//RUuLi4AgBs3bqCgoABBQUF1rkMikcDBwaHOj78XNaoOxTnaWRtl/w2Fvb09+zNj7M+8sT/zxv7qTt9DWICJz8aysbFBbGwsli9fjkOHDiE5ORnTp0+Hr68vBgwYALVajZycHJSXlwMABg8eDDc3N8THx+PKlStITExEXFwcIiMj0bdvX1O2UqsyRSUAXj2ZiIjIlEx+UcG4uDiMGDECc+fOxciRIyGVSrFp0ybIZDJkZGSgZ8+e2L9/PwDAzc0NH3/8MQBg5MiRmDp1KsLDw7Fp0yZIpVJTtlGrsvKqsONgZ9IBNCIiokbN5O/CUqkU8fHxiI+Pr7EuICAAly5d0lnWsmVLbNiwob7KeyhlChUAnnZORERkSiYf2bFk1WHH0d7kmZKIiKjRYtgxor8PY3Fkh4iIyFQYdoyorPzOyA7n7BAREZkMw44R8WwsIiIi02PYMaLqw1gc2SEiIjIdhh0jkpfzbCwiIiJTY9gxourDWLzODhERkekw7BhRqfbUc47sEBERmQrDjpEIggA55+wQERGZHMOOkZQr1VBrBAAc2SEiIjIlhh0jqb56spUEsJXxx0xERGQqfBc2kur5OnY2VqJuQ09ERESGxbBjJNUjO/Y2/BETERGZEt+JjURmXfWjdXOSmrgSIiKixo2nCRlJm2ZumPNcR5QXZ5i6FCIiokaNIztGIpFI0KGNF1wdmCeJiIhMiWGHiIiILBrDDhEREVk0hh0iIiKyaAw7REREZNEYdoiIiMiiMewQERGRRWPYISIiIovGsENEREQWjWGHiIiILBrDDhEREVk0hh0iIiKyaAw7REREZNEYdoiIiMiiSQRBEExdhCmdPn0agiDAxsbG4PsWBAEqlQoymQwSicTg+zc19mfe2J95Y3/mjf09PKVSCYlEgk6dOj1wW2ujVGBGjPlLJpFIjBKiGgr2Z97Yn3ljf+aN/RnmOfR9D2/0IztERERk2Thnh4iIiCwaww4RERFZNIYdIiIismgMO0RERGTRGHaIiIjIojHsEBERkUVj2CEiIiKLxrBDREREFo1hh4iIiCwaww4RERFZNIYdIiIismgMO0RERGTRGHaMQKPR4IMPPkCvXr3QoUMHTJw4Eenp6aYuq84KCwsxb9489O7dG506dcLIkSORmJioXT9u3DiEhITofIwZM8aEFYuTlZVVo/6QkBB8/fXXAICkpCTExsaiQ4cOiImJwSeffGLiivV3/PjxWnsLCQlBv379AADr1q2rdb052LBhQ43ftQe9Xub091lbf4cPH8bw4cPRsWNHxMTEYOnSpSgvL9euP3XqVK2v5/Hjx+u7/Aeqrb+5c+fWqD0mJka73pxfvzFjxtzz73H37t0AALVajcjIyBrr16xZY6IudD3o/eD333/HsGHD0L59ewwaNAj79u3TeXxFRQXeeecddO/eHR07dsSMGTOQn59v/MIFMrg1a9YI3bp1E44cOSIkJSUJ48ePFwYMGCBUVFSYurQ6GTdunDB48GDh5MmTwrVr14R33nlHiIyMFK5evSoIgiB0795d2L59u5Cdna39KCgoMG3RIhw9elSIiIgQsrKydHpQKBRCfn6+0K1bN2HOnDlCSkqKsHPnTiEiIkLYuXOnqcvWS0VFhU5P2dnZwoEDB4SQkBBtD6+88ooQHx9fY7uGbtu2bUJoaKgQGxurXabP62Uuf5+19Xfy5EkhLCxMWLdunXD9+nXh6NGjQu/evYXZs2drt/nss8+E/v3713g9zaE/QRCEESNGCCtWrNCpPS8vT7venF+/goICnb6ysrKEUaNGCU888YRQWloqCIIgpKSkCMHBwUJSUpLOttXrTe1+7wcpKSlCRESEsGLFCiElJUX46KOPhPDwcOG3337TPn727NlC//79hZMnTwp//fWXMHToUGH06NFGr5thx8AqKiqEjh07Cp999pl2WVFRkRAZGSns3bvXhJXVTWpqqhAcHCwkJiZql2k0GqF///7CqlWrhNzcXCE4OFi4cOGCCat8OBs3bhSGDBlS67r169cLPXv2FFQqlXbZf//7X2HAgAH1VZ5BlZWVCX379tV5c/zXv/4lbNmyxXRFiZSZmSlMnjxZ6NChgzBo0CCdN5MHvV7m8Pd5v/5mzJghPP/88zrbf/PNN0Lbtm21b/bz588XXnzxxXqtWYz79afRaIQOHToIBw4cqPWx5v76/dOnn34qtGvXTvsfR0EQhH379gmdOnWqj1JFe9D7wVtvvSWMGDFC5zGvvfaaMH78eEEQqn42oaGhwtGjR7Xrr127JgQHBwunT582au08jGVgycnJKCsrQ/fu3bXLXFxcEB4ejpMnT5qwsrpxd3fHxo0bERERoV0mkUggkUhQXFyMS5cuQSKRoGXLlias8uFcunQJQUFBta5LTExE165dYW1trV32yCOPIDU1Fbm5ufVVosGsX78eCoUCs2bNAgAolUqkpqaiVatWJq5MfxcuXIBMJsO3336L9u3b66x70OtlDn+f9+tv/Pjx2teumpWVFVQqFUpLSwHc//e5Ibhffzdu3IBcLr/n76O5v353y8/Px6pVq/DSSy/p9NuQX78HvR8kJibqvDZA1d/fqVOnIAgCTp06pV1WrWXLlvDx8TH662f94E1IjMzMTACAn5+fznJvb2/tOnPi4uKCPn366Cz7v//7P6SlpeGNN97A5cuX4ezsjAULFuDYsWNwcHDAoEGDMGXKFNjY2JioanEuX74Md3d3jB49GtevX0eLFi3w0ksvoXfv3sjMzERwcLDO9t7e3gCAjIwMeHl5maLkOsnPz8fWrVsxY8YMuLm5AQBSUlKgVqvxf//3f3jvvfdQUVGBqKgoxMfHa/tsaGJiYnTmcNztQa+XOfx93q+/8PBwne9VKhW2bt2Kdu3awcPDAwBw5coVuLu7Y9iwYcjKykJwcDCmT5+OyMhIo9euj/v1d/nyZQDAp59+ip9//hlWVlbo3bs3pk+fDmdnZ7N//e724Ycfws7ODi+88ILO8suXL6OyshIvvPACkpOT4ePjg7Fjx+Kpp54yVsl6e9D7wTfffANfX1+d9d7e3lAoFCgoKEBWVhbc3d1ha2tbYxtjv34c2TEwhUIBADXe6G1tbVFRUWGKkgzq9OnTmDNnDgYMGIDo6GhcvnwZFRUViIyMxEcffYSXXnoJX331FebOnWvqUvVSWVmJa9euoaioCNOmTcPGjRvRoUMHTJo0Cb///jvKy8trfS0BmN3ruX37djg7O+PZZ5/VLqt+c7G3t8fq1avx3nvv4dq1a3juued0Jr2aiwe9Xpb091lZWYnXX38dV65cwfz58wFUBbqSkhLI5XLMnTsXCQkJ8PLyQmxsLFJSUkxc8YNdvnwZVlZW8Pb2xvr16zF79mz8+uuvmDJlCjQajcW8fqWlpfjyyy/xwgsv1Hjjv3LlCgoLCzFmzBhs2rQJAwcOxJw5c7Bz504TVXtv/3w/qO3vr/p7pVIJhUJR63+C6+P148iOgdnZ2QGoemGrvwaq/qG1t7c3VVkGcfDgQcycOROdOnXC8uXLAQALFizArFmz4OrqCgAIDg6GTCbD9OnT8frrrzf4kQ9ra2scP34cUqlU+3q1a9cOV65cwaZNm2BnZwelUqnzmOo/SgcHh3qv92Hs3r0bQ4cO1fm9HDp0KHr37q0dFQCANm3aoHfv3jh8+DAef/xxU5RaZw96vSzl77O0tBSvvvoqTpw4gbVr12pHbfz8/HDy5EnY29tDJpMBACIiInDx4kV8+umneOedd0xZ9gO99NJLGDVqFNzd3QFU/XvSpEkT/Pvf/8a5c+cs5vU7ePAglEolhg8fXmPdd999B7VaDUdHRwBAaGgobt++jU2bNmHEiBH1Xeo91fZ+YGtrW+Pvr/p7e3v7Wv8+gfp5/TiyY2DVw6vZ2dk6y7Ozs+Hj42OKkgxi27ZtmDZtGvr27Yv169dr/zdibW2tDTrV2rRpAwANZlj5QRwdHXX+4QSqesjKyoKvr2+tryUAs3o9k5OTkZ6ejiFDhtRYd3fQAaqGlN3c3Mzm9bvbg14vS/j7zM7OxujRo/Hnn39i06ZNNQ4ruLi4aIMOUDWnJygoCFlZWfVdqmhWVlbaoFPt7n9PLOH1A6qCQp8+feDi4lJjnZ2dnTboVAsODm5Qf4/3ej/w8/Or9bVxcHCAs7MzfH19UVhYWCPw1Mfrx7BjYKGhoXByctK5pkVxcTEuXryIqKgoE1ZWd9u3b8e7776L0aNHY8WKFTrDkGPGjMGcOXN0tj937hxkMhkCAwPruVLxrly5gk6dOtW4Bsn58+fRunVrREVF4dSpU1Cr1dp1f/zxB1q2bAlPT8/6LrfOEhMT4enpidDQUJ3lK1euxMCBAyEIgnbZzZs3UVBQgNatW9d3mQ/tQa+Xuf99FhUVYezYscjPz8dnn31Wo+aff/4ZHTt21LnuTGVlJZKTk83i9Xz99dfx/PPP6yw7d+4cAKB169Zm//pVq20iL1DVS9euXbXX+Kp27tw5begztfu9H3Tp0gUnTpzQ2f6PP/5Ap06dYGVlhc6dO0Oj0WgnKgPA9evXkZWVZfTXj2HHwGxsbBAbG4vly5fj0KFDSE5OxvTp0+Hr64sBAwaYujzRrl+/jkWLFuGxxx7D5MmTkZubi5ycHOTk5KCkpAQDBw7Enj178PnnnyM9PR379+/H+++/jxdeeAFOTk6mLv+BgoKC0KpVKyxYsACJiYm4evUqFi9ejD///BMvvfQShg8fjtLSUrz55ptISUnB119/ja1bt2Ly5MmmLl2Uixcv1nqhwMceewy3bt3C22+/jevXr+PkyZOYNm0aOnXqhF69epmg0ofzoNfL3P8+Fy9ejPT0dCxbtgweHh7av8WcnByo1Wp06tQJ7u7umDVrFs6fP49Lly5h1qxZKCwsrBEiGqKBAwfi999/x9q1a3Hjxg389NNPeOONNzB48GAEBQWZ/esHVM2rKigoqPEfD6BqVO6RRx7BypUr8dNPPyE1NRUbN27Et99+i2nTppmgWl0Pej8YM2YMzp49i+XLl+Pq1avYvHkzfvjhB0yYMAFA1ejqE088gblz5+L48eM4e/YsXnvtNXTt2hUdOnQwau2cs2MEcXFxqKysxNy5c1FeXo6oqChs2rRJZ2jZXPzf//0fVCoVfvzxR/z44486655++mksWbIEEokEn376KRYtWoQmTZrg+eefx6RJk0xUsThWVlZYv349/vvf/+LVV19FcXExwsPDsWXLFu1ZPR999BHee+89PP3002jSpAlef/11PP300yauXJycnBztGVh3a9euHT788EOsXr0aw4YNg42NDfr164dZs2ZBIpHUf6EPydPT84Gvl7n+farVauzfvx8qlQpjx46tsf7QoUMICAjA1q1bsXz5crzwwguoqKhA586dsW3btgY/fw4A+vXrh1WrVmHjxo348MMP4ezsjCFDhuDVV1/VbmOur1+1nJwcAKj17xEAFi1ahDVr1mD+/PnIy8tDUFCQ9orRpqbP+0FCQgKWLVuGjz/+GAEBAVi2bJnOKNa7776LRYsW4eWXXwYA9O7du15OaJEId49fExEREVkYHsYiIiIii8awQ0RERBaNYYeIiIgsGsMOERERWTSGHSIiIrJoDDtERERk0Rh2iIgIAMArkZClYtghIh1ff/01QkJCcPPmTVOXUsPWrVvx6KOPIjIyEgkJCaYux2IUFxfj9ddfR2JioqlLITIKhh0iMgulpaVYunQpIiMjsWnTJrO7inVDlpSUhD179kCj0Zi6FCKj4O0iiMgsFBUVQaPRoH///mZ100ciMj2O7BA1MDExMfjggw+wdOlS9OjRA5GRkXjhhReQmpqq3WbMmDEYM2aMzuOOHz+OkJAQ7R2hv/76a0RERCAxMRHDhw9HREQEBg4ciMOHD+PatWsYO3Ys2rdvj8ceewz79u2rUcfp06cxdOhQtGvXDoMHD8b+/ft11ldUVOD9999Hnz590K5dOwwZMqTGNjExMVi0aBHGjh2LyMhIvPnmm/fs+9ixYxg1ahQ6d+6Mbt26YcaMGcjIyND2EhMTAwB44403ar2pabXS0lK8++676NWrFzp06IDhw4fj6NGj2vVqtRqfffYZhgwZgsjISERHR2P58uWoqKjQbjN79my88MIL+OKLL9C/f39ERkbiP//5D65fv44jR45gyJAhaN++PZ555hkkJSXpPG7MmDHYuXMn+vbti44dO2Ls2LFITk7WqTE1NRVxcXF49NFH0aFDB4wZM0bnTtA3b95ESEgIvv/+e8TFxaFjx47o2rUr5s6dC7lcrrOvr776Ck888QTatWuH6OhorFmzRueu77Nnz8bzzz+PXbt2YeDAgWjXrh2eeuop/PzzzwCqfm+ee+45AMBzzz2n/b26ceMGXnzxRXTr1g3t27fHs88+i59++umeP3eihoxhh6gB+uSTT3Dt2jUsXrwYCxcuxPnz5zFr1izR+6msrMSMGTPwn//8B+vWrYO9vT1mzpyJF198EdHR0Vi/fj28vb0xa9YsZGZm6jx23rx5+Ne//oWEhAS0adMG06dPx8GDBwFUTWSdOnUqduzYgXHjxmHdunXo2LEjpk+fjt27d+vs57PPPkNERAQSEhIwYsSIWuvcvXs3xo8fDz8/P6xYsQJz5szBmTNn8OyzzyIvLw/R0dFYu3YtAOCll17CF198Uet+1Go1xo8fj71792Ly5MlISEhAq1atMHXqVO18lHnz5mHx4sXo378/1q1bh9GjR2Pbtm2YMmWKzgTdM2fOYNu2bZg9ezYWL16Mq1evYtKkSVi8eDEmT56MFStWICMjAzNnztSpISkpCStXrsTLL7+MZcuWoaCgALGxscjOzgYApKSkYNiwYbh58ybmzp2L5cuXQyKRYOzYsThx4oTOvubPnw9/f38kJCTghRdewM6dO7Fu3Trt+g0bNuCtt95C9+7dsX79eowePRoffvgh3nrrLZ39nD9/Hps2bUJcXBz+97//QSqVYtq0aSgqKkLbtm0xb9487c9m/vz50Gg0mDx5MhQKBd5//30kJCTAzc0NL730EtLS0mr92RM1aAIRNSh9+/YV+vbtK1RWVmqXrVmzRggODhby8/MFQRCE2NhYITY2Vudxf/zxhxAcHCz88ccfgiAIwq5du4Tg4GBh+/bt2m327dsnBAcHC6tWrdIuO3funBAcHCz8+OOPOo/76KOPdPY/dOhQ4emnnxYEQRB+/fVXITg4WNi3b5/ONjNnzhQeffRRQaVSaXvp37//fftVq9XCo48+KowfP15neVpamtC2bVth6dKlgiAIQnp6uhAcHCzs2rXrnvs6fPiwTi/V+3/22WeFNWvWCFeuXBGCg4OFDRs26Dxu9+7dQnBwsHD06FFBEARh1qxZQnBwsJCSkqLdZt68eUJwcLDw22+/aZdt2rRJCA4OFoqKinQed/LkSe02WVlZQkREhLBs2TJBEAThlVdeEbp16yaUlJRot1GpVMLAgQOF4cOH6/Q6c+ZMnTrHjBkjDB48WBAEQSguLhYiIyOFefPm6Wzz5ZdfCsHBwcLly5d1akpLS9Nuc+LECSE4OFj44YcfBEGo+buTnZ0tBAcHC99++632McXFxcKiRYu0+yUyJxzZIWqAIiIiIJVKtd/7+voCABQKheh9dezYUfu1p6cnAKB9+/baZW5ubgCqzsi52+OPP67zff/+/XHx4kWUlZXh999/h0QiQZ8+fVBZWan9iImJQU5ODq5cuaJ9XFhY2H3ru379OnJycjB48GCd5c2bN0fHjh1rjHbcz6lTpyCTybSHvADAysoKO3bswMsvv6zd1xNPPKHzuCeeeAJSqVR7CBAAXF1dERQUpP3ey8sLwIN/dgEBAejSpYv2e29vb3Ts2BEnT54EAJw4cQJ9+/aFk5OTdhtra2s88cQTOH/+PMrKyrTLO3TooFOnr6+v9jDWmTNnUF5ejpiYmBqvAVB1WLCah4cHmjdvrrMf4N6/T15eXmjdujXeeustzJo1C3v37oVGo8GcOXPQpk2bWh9D1JBxgjJRA2Rvb6/zvZVV1f9L6nK2zN1vqvfaf22q39yreXp6QhAElJaWorCwEIIgoFOnTrU+Njs7WxtyHBwc7vs8hYWFtT5f9bKLFy8+sNa79+Xm5qb9ef1TUVERAKBJkyY6y62treHu7o6SkhLtstp+bsCD+/Hx8amxzNPTExcuXNDWcK9eq3++1Wr7PRDuHGqr/rlNmjSp1jqqD5vVth+JRALg3r9PEokEmzdvxrp16/Djjz9i9+7dkMlk6N+/P9555x24urrW+jiihophh8hM3T0JFUCNiasP659vyrm5uZBKpXB1dYWzszMcHBzwySef1PrYFi1a6P081aMjubm5Ndbl5OTA3d1d7305Oztrg1j1GzoAXLx4EYIgaN+kc3Jy4O/vr12vUqlQUFAg6rnupaCgoMay3Nxc7aiaq6vrPXsFAHd3d52gci8uLi4AgOXLlyMwMLDG+toClRg+Pj54++23MX/+fCQnJ+OHH37Ahx9+CHd3d8yfP/+h9k1U33gYi8gMOTk51ZhQfPfZPIZw9xlMGo0GP/zwA9q3bw87Ozt07doVcrkcgiAgIiJC+3H58mX873//Q2Vlpd7P07JlSzRp0gTfffedzvL09HT8+eef9xw9qk2XLl2gUqm0ZxoBVZOp58yZgw0bNqBr164AUOPss3379kGtVqNz5856P9e9pKam4urVq9rvs7KycObMGXTv3h0AEBUVhSNHjuiM4KjVauzbtw8RERGwsbHR63nat28PmUyGrKwsndfA2toaK1asEHVRyLsPmQJVh8h69OiBs2fPQiKRICwsDNOnT0dwcDBu376t936JGgqO7BCZob59++Lw4cNYvHgxYmJikJiYWOMsqIe1atUqqNVq+Pn54fPPP8f169exZcsWAECfPn0QFRWFKVOmYMqUKQgKCsLZs2fxwQcfoFevXvDw8ND7eaysrPDaa69hzpw5mDFjBp588kkUFBRg7dq1cHV1xbhx4/TeV3R0NDp27IjZs2fj1VdfRbNmzbBnzx5cvXoV7777Llq3bo2nn34aH3zwARQKBaKiopCUlIS1a9eiW7du6NWrl+if0z8JgoAXX3wR06dPh1Qq1fZRfUr3yy+/jJ9//hnPPfccJk2aBJlMhm3btiE9PR0fffSR3s/j7u6OCRMmYPXq1SgtLUW3bt2QlZWF1atXQyKRIDQ0VO99OTs7A6gKuK6urggPD4ednR1ef/11TJs2DV5eXvjtt9+QlJSkPU2dyJww7BCZoeHDh+PGjRv45ptvsGPHDkRFReGDDz7AyJEjDfYcixcvxpIlS5CWlobg4GB8+OGH2pERKysrbNy4EatXr8aGDRuQl5cHHx8fjBs3DlOnThX9XMOGDYOjoyM2bNiAqVOnwsnJCb169cJrr71WY37N/UilUnz44YdYvnw5Vq9eDYVCgZCQEGzevBmRkZEAgPfeew8tWrTArl278OGHH8Lb2xvPPfccpkyZcs+5PmI0bdoU48ePx6JFi6BQKNCjRw+sW7dOe7iuTZs22L59u/YUe4lEgsjISHzyySc6E5v18eqrr6JJkybYvn07PvroI7i6uqJ79+547bXXtAFGH23atMHgwYPx2Wef4ZdffsF3332HzZs347///S/ee+89FBcXIzAwEAsWLMCwYcNE1UjUEEgEgXd+IyIyhNmzZ+PEiRM4fPiwqUshortwzg4RERFZNIYdIiIismg8jEVEREQWjSM7REREZNEYdoiIiMiiMewQERGRRWPYISIiIovGsENEREQWjWGHiIiILBrDDhEREVk0hh0iIiKyaAw7REREZNH+HzqF0vs6Xr5yAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca_test = KernelPCA()\n",
    "kpca_test = kpca_test.fit_transform(X_train)\n",
    "explained_variance = np.var(kpca_test, axis=0)\n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "display(plt.show())\n",
    "\n",
    "evr = explained_variance_ratio\n",
    "cvr = np.cumsum(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cumulative Variance Ratio</th>\n",
       "      <th>Explained Variance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.901335</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.902856</td>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.905842</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.907310</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cumulative Variance Ratio  Explained Variance Ratio\n",
       "78                    0.901335                  0.001534\n",
       "79                    0.902856                  0.001521\n",
       "80                    0.904359                  0.001503\n",
       "81                    0.905842                  0.001482\n",
       "82                    0.907310                  0.001469\n",
       "..                         ...                       ...\n",
       "197                   0.999251                  0.000364\n",
       "198                   0.999594                  0.000343\n",
       "199                   0.999918                  0.000324\n",
       "200                   0.999971                  0.000052\n",
       "201                   1.000000                  0.000029\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kpca_df = pd.DataFrame()\n",
    "kpca_df['Cumulative Variance Ratio'] = cvr\n",
    "kpca_df['Explained Variance Ratio'] = evr\n",
    "display(kpca_df[kpca_df['Cumulative Variance Ratio'] >= 0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above table, we can conclude that even if we use approx. half the number of components using Kernalized PCA, our new dataset will have a Cumulative Variance as 90% of the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf9ddb",
   "metadata": {},
   "source": [
    "# KPCA Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:3500]\n",
    "y_test = y_test[:3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eaddc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components=100)\n",
    "X_train = kpca.fit_transform(X_train)\n",
    "X_test = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6c7a577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50),\n",
       "             learning_rate=&#x27;adaptive&#x27;, max_iter=500, random_state=42,\n",
       "             validation_fraction=0.2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50),\n",
       "             learning_rate=&#x27;adaptive&#x27;, max_iter=500, random_state=42,\n",
       "             validation_fraction=0.2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(alpha=5e-05, early_stopping=True, hidden_layer_sizes=(50, 50),\n",
       "             learning_rate='adaptive', max_iter=500, random_state=42,\n",
       "             validation_fraction=0.2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 955.990888657508\n",
      "Root Mean Squared Error (RMSE): 30.91910232619162\n",
      "Mean Absolute Error (MAE): 15.398330761501565\n",
      "R-squared (RÂ²): 0.21709931925488557\n",
      "Explained Variance Score: 0.21829851443570392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# R-squared (RÂ²) or Coefficient of Determination\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (RÂ²):\", r2)\n",
    "\n",
    "# Explained Variance Score\n",
    "explained_var = explained_variance_score(y_test, y_pred)\n",
    "print(\"Explained Variance Score:\", explained_var)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
