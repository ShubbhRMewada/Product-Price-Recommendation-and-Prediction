{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-7qovRrodq",
    "outputId": "ef79fceb-0fb0-4e1e-944d-3c794e23e338",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install gensim\n",
    "# !pip install python-Levenshtein\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import collections\n",
    "# from wordcloud import STOPWORDS\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import string\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the next cell only if you want to train the model. \n",
    "# If already trained, Skip to the next cell and directly load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pQVgxtersseC"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"preprocessed_tokenized_training_data.csv\")\n",
    "train_data['concatenated_description'] = train_data['concatenated_description'].map(str)\n",
    "train_data_idf = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GInA3QoeJl9c"
   },
   "outputs": [],
   "source": [
    "train_data['concatenated_description'] = train_data['concatenated_description'].apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QpwHNf5dJ1Sv"
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Build the Word2Vec model\n",
    "# Continous bag of words\n",
    "# Train the Word2Vec model\n",
    "\n",
    "model2 = Word2Vec(vector_size=200, window=5, min_count=1, sg=0, workers=cores-1)\n",
    "model2.build_vocab(train_data['concatenated_description'], progress_per=1000)\n",
    "t = time.time()\n",
    "model2.train(train_data['concatenated_description'], total_examples=model2.corpus_count, epochs=20)\n",
    "print('Time to build vocab for Model-2: {} mins'.format(round((time.time() - t) / 60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jIy1sBOEOyu7"
   },
   "outputs": [],
   "source": [
    "model2.save(\"word2vec_cbow_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One can directly load the model from here instead of training the models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYAkgFhiOytT",
    "outputId": "d42bb6bc-14be-4a56-c6e5-8ca71172fd27"
   },
   "outputs": [],
   "source": [
    "#Loading a pretrained model\n",
    "\n",
    "model2 = Word2Vec.load(\"word2vec_cbow_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec2(doc):\n",
    "    return np.mean([model2.wv[word] for word in doc if word in model2.wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2 = train_data.copy()\n",
    "\n",
    "series = train_data_model2.concatenated_description.apply(avg_word2vec2)\n",
    "\n",
    "df = pd.DataFrame(series.apply(pd.Series))\n",
    "\n",
    "train_data_model2 = pd.concat([train_data_model2, df], axis=1)\n",
    "\n",
    "train_data_model2 = train_data_model2.drop(['concatenated_description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2.to_csv('avgword2vec_cbow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2 = pd.read_csv('avgword2vec_cbow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_model2.drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'train_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100559</td>\n",
       "      <td>-0.614330</td>\n",
       "      <td>0.208602</td>\n",
       "      <td>0.571966</td>\n",
       "      <td>-0.131203</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>0.608419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075749</td>\n",
       "      <td>0.193744</td>\n",
       "      <td>0.494159</td>\n",
       "      <td>-0.073508</td>\n",
       "      <td>0.494414</td>\n",
       "      <td>-0.169989</td>\n",
       "      <td>0.131777</td>\n",
       "      <td>0.145828</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>-0.127633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.329170</td>\n",
       "      <td>-0.350506</td>\n",
       "      <td>0.272558</td>\n",
       "      <td>0.105843</td>\n",
       "      <td>1.208020</td>\n",
       "      <td>1.528792</td>\n",
       "      <td>-0.091454</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.339325</td>\n",
       "      <td>0.835479</td>\n",
       "      <td>0.271060</td>\n",
       "      <td>0.437964</td>\n",
       "      <td>1.127263</td>\n",
       "      <td>1.099126</td>\n",
       "      <td>-0.569234</td>\n",
       "      <td>-0.982572</td>\n",
       "      <td>-0.126194</td>\n",
       "      <td>-0.116404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.240003</td>\n",
       "      <td>-0.041858</td>\n",
       "      <td>0.145329</td>\n",
       "      <td>0.452647</td>\n",
       "      <td>0.760089</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.452785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418078</td>\n",
       "      <td>0.219362</td>\n",
       "      <td>0.174552</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>-0.374551</td>\n",
       "      <td>-0.620355</td>\n",
       "      <td>0.631266</td>\n",
       "      <td>-0.212377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101531</td>\n",
       "      <td>-0.345377</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.361317</td>\n",
       "      <td>-0.764579</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.777097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010613</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>1.474908</td>\n",
       "      <td>0.728149</td>\n",
       "      <td>1.006546</td>\n",
       "      <td>-0.213868</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>-0.457993</td>\n",
       "      <td>-0.727977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820777</td>\n",
       "      <td>-0.600387</td>\n",
       "      <td>-0.174789</td>\n",
       "      <td>-0.790316</td>\n",
       "      <td>0.611780</td>\n",
       "      <td>0.271854</td>\n",
       "      <td>0.250769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>0.078621</td>\n",
       "      <td>-0.048399</td>\n",
       "      <td>-0.540433</td>\n",
       "      <td>0.852686</td>\n",
       "      <td>0.234550</td>\n",
       "      <td>-0.283534</td>\n",
       "      <td>-0.156189</td>\n",
       "      <td>0.549295</td>\n",
       "      <td>-0.314060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370407</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484753</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.842793</td>\n",
       "      <td>-0.549632</td>\n",
       "      <td>0.861718</td>\n",
       "      <td>1.395888</td>\n",
       "      <td>1.131525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391027</td>\n",
       "      <td>0.211749</td>\n",
       "      <td>-0.072331</td>\n",
       "      <td>1.241811</td>\n",
       "      <td>2.145595</td>\n",
       "      <td>1.513619</td>\n",
       "      <td>1.109203</td>\n",
       "      <td>-1.061759</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>-1.878718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370408</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.989117</td>\n",
       "      <td>-0.492069</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>0.631189</td>\n",
       "      <td>1.291212</td>\n",
       "      <td>-0.071031</td>\n",
       "      <td>0.779076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386589</td>\n",
       "      <td>0.272975</td>\n",
       "      <td>-0.883474</td>\n",
       "      <td>-0.305047</td>\n",
       "      <td>-1.207003</td>\n",
       "      <td>0.288548</td>\n",
       "      <td>-1.372537</td>\n",
       "      <td>-0.139790</td>\n",
       "      <td>1.139007</td>\n",
       "      <td>0.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370409</th>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.060849</td>\n",
       "      <td>0.345536</td>\n",
       "      <td>0.088263</td>\n",
       "      <td>0.149190</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.373666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325529</td>\n",
       "      <td>0.767687</td>\n",
       "      <td>0.523542</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.218952</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>-0.767223</td>\n",
       "      <td>0.097173</td>\n",
       "      <td>-0.474679</td>\n",
       "      <td>-0.750847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370410</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263113</td>\n",
       "      <td>-0.582247</td>\n",
       "      <td>0.410359</td>\n",
       "      <td>-0.201431</td>\n",
       "      <td>0.439368</td>\n",
       "      <td>1.350481</td>\n",
       "      <td>0.880811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339725</td>\n",
       "      <td>0.607348</td>\n",
       "      <td>-0.159939</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>1.756508</td>\n",
       "      <td>0.985768</td>\n",
       "      <td>0.587361</td>\n",
       "      <td>-0.796640</td>\n",
       "      <td>-0.361518</td>\n",
       "      <td>-1.248246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370411</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.829921</td>\n",
       "      <td>-0.804902</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.184616</td>\n",
       "      <td>0.737504</td>\n",
       "      <td>1.492387</td>\n",
       "      <td>-0.328706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602713</td>\n",
       "      <td>-0.324386</td>\n",
       "      <td>-0.225616</td>\n",
       "      <td>0.208637</td>\n",
       "      <td>-0.016791</td>\n",
       "      <td>-0.252122</td>\n",
       "      <td>-0.543555</td>\n",
       "      <td>0.542459</td>\n",
       "      <td>-0.926188</td>\n",
       "      <td>-1.731979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370412 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_condition_id  price  shipping         0         1         2  \\\n",
       "0                       2    8.0         1 -0.100559 -0.614330  0.208602   \n",
       "1                       3   14.0         0 -0.329170 -0.350506  0.272558   \n",
       "2                       1   25.0         1 -0.240003 -0.041858  0.145329   \n",
       "3                       3   25.0         0 -0.101531 -0.345377 -0.117154   \n",
       "4                       1   12.0         1  0.820777 -0.600387 -0.174789   \n",
       "...                   ...    ...       ...       ...       ...       ...   \n",
       "370407                  1   20.0         1  0.484753  0.030433 -0.842793   \n",
       "370408                  1   44.0         0 -0.989117 -0.492069 -0.002195   \n",
       "370409                  3   15.0         1  0.183705  0.060849  0.345536   \n",
       "370410                  1   16.0         0 -0.263113 -0.582247  0.410359   \n",
       "370411                  1   17.0         1 -1.829921 -0.804902  0.084474   \n",
       "\n",
       "               3         4         5         6  ...       190       191  \\\n",
       "0       0.571966 -0.131203  0.016526  0.608419  ... -0.075749  0.193744   \n",
       "1       0.105843  1.208020  1.528792 -0.091454  ... -1.339325  0.835479   \n",
       "2       0.452647  0.760089  0.097341  0.452785  ...  0.418078  0.219362   \n",
       "3      -0.361317 -0.764579  0.917608  0.777097  ... -0.010613  0.054686   \n",
       "4      -0.790316  0.611780  0.271854  0.250769  ... -0.093859  0.078621   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "370407 -0.549632  0.861718  1.395888  1.131525  ... -0.391027  0.211749   \n",
       "370408  0.631189  1.291212 -0.071031  0.779076  ...  0.386589  0.272975   \n",
       "370409  0.088263  0.149190  0.014507  0.373666  ... -0.325529  0.767687   \n",
       "370410 -0.201431  0.439368  1.350481  0.880811  ... -0.339725  0.607348   \n",
       "370411  0.184616  0.737504  1.492387 -0.328706  ...  0.602713 -0.324386   \n",
       "\n",
       "             192       193       194       195       196       197       198  \\\n",
       "0       0.494159 -0.073508  0.494414 -0.169989  0.131777  0.145828  0.024475   \n",
       "1       0.271060  0.437964  1.127263  1.099126 -0.569234 -0.982572 -0.126194   \n",
       "2       0.174552 -0.024960 -0.002166  0.013162 -0.374551 -0.620355  0.631266   \n",
       "3       0.057820  1.474908  0.728149  1.006546 -0.213868  0.185430 -0.457993   \n",
       "4      -0.048399 -0.540433  0.852686  0.234550 -0.283534 -0.156189  0.549295   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "370407 -0.072331  1.241811  2.145595  1.513619  1.109203 -1.061759  0.059616   \n",
       "370408 -0.883474 -0.305047 -1.207003  0.288548 -1.372537 -0.139790  1.139007   \n",
       "370409  0.523542  0.516035  0.218952  0.475278 -0.767223  0.097173 -0.474679   \n",
       "370410 -0.159939  0.906151  1.756508  0.985768  0.587361 -0.796640 -0.361518   \n",
       "370411 -0.225616  0.208637 -0.016791 -0.252122 -0.543555  0.542459 -0.926188   \n",
       "\n",
       "             199  \n",
       "0      -0.127633  \n",
       "1      -0.116404  \n",
       "2      -0.212377  \n",
       "3      -0.727977  \n",
       "4      -0.314060  \n",
       "...          ...  \n",
       "370407 -1.878718  \n",
       "370408  0.010722  \n",
       "370409 -0.750847  \n",
       "370410 -1.248246  \n",
       "370411 -1.731979  \n",
       "\n",
       "[370412 rows x 203 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"avgword2vec_sg.csv\" --> Will be used for \"train_test_split\", Contains 0.03 of entire dataset. \n",
    "## Generated from extracting dataset \"preprocessed_tokenized_training_data.csv\" and then applying \"word2vec_cbow_model\" on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've our dataset ready for the Model-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_model2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e69f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['price']\n",
    "X = data.drop(columns=['price'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1014.9341455514044\n",
      "Root Mean Squared Error (RMSE): 31.858031099730635\n",
      "Mean Absolute Error (MAE): 14.497321434480302\n",
      "R-squared (R²): 0.30077352232958443\n",
      "Explained Variance Score: 0.30077761600135844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# R-squared (R²) or Coefficient of Determination\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R²):\", r2)\n",
    "\n",
    "# Explained Variance Score\n",
    "explained_var = explained_variance_score(y_test, y_pred)\n",
    "print(\"Explained Variance Score:\", explained_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 1068.2573600530848\n",
      "Root Mean Squared Error (RMSE): 32.68420658442063\n",
      "Standard Deviation of MSE: 75.33574617235763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "num_folds = 5\n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Cross-validation returns negative mean squared error, so we take the absolute values\n",
    "mse_scores = -scores\n",
    "\n",
    "# Compute the mean and standard deviation of the cross-validation scores\n",
    "mean_mse = mse_scores.mean()\n",
    "std_mse = mse_scores.std()\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_mse)\n",
    "# Print the results\n",
    "print(\"Mean MSE:\", mean_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Standard Deviation of MSE:\", std_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model4.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(xgb, file)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
